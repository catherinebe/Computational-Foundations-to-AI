{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1_tosubmit",
      "provenance": [],
      "collapsed_sections": [
        "jfyajknzeyZc",
        "9VK1diFTnp57",
        "gnPbURqPnnqH"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnBqyxBOyuI1NvQ3zizYVB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfyajknzeyZc"
      },
      "source": [
        "Catherine Berrouet, Z23353674\n",
        "\n",
        "Computational Foundations of AI, Fall 2020\n",
        " \n",
        "Assignment 1\n",
        "\n",
        "# Task: Ridge Regression Fit\n",
        "(From Sratch using Python)\n",
        "\n",
        "You may **not** use a library that can perform *gradient descent, cross validation, ridge regression, least squares regression, optimization, etc.* to successfully complete this programing assignment. The goal of this assignment is not to learn how to use particular libraries of a language, but it is to instead understand how key methods in statistical machine learning are implemented. \n",
        " \n",
        "\n",
        "---\n",
        "\n",
        "Opportunity for 10% extra credit if you additionally implement the assignment using built- in statistical or machine learning libraries (see Deliverable 6 at end of the document).\n",
        "\n",
        "---\n",
        "\n",
        "In this assignment you will be analyzing credit card data from ùëÅ = 400 training observations. The goal is to fit a model that can predict credit balance based on ùëù = 9 features describing an individual, which include an individual‚Äôs income, credit limit, credit rating, number of credit cards, age, education level, gender, student status, and marriage status. \n",
        "\n",
        "**Specifically, you will perform a penalized (regularized) least squares fit of a linear model using ridge regression, with the model parameters obtained by batch gradient descent. The tuning parameter will be chosen using five-fold cross validation, and the best-fit model parameters will be inferred on the training dataset conditional on an optimal tuning parameter.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v5KzsiPx9y0"
      },
      "source": [
        "# Import Data and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-ao7VVfq3aI"
      },
      "source": [
        "# Import Python libraries for data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Libraries for plotting\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "# import seaborn as sns"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FagvOmmZq_61",
        "outputId": "a23993a8-ce6c-410d-a8c8-05be307a6460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import data from csv file uploaded onto google drive\n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Computational AI/Credit_N400_p9.csv')\n",
        "#data = pd.read_csv('/content/Credit_N400_p9.csv') #manual upload csv data file\n",
        "data #prints data for viewing"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Income</th>\n",
              "      <th>Limit</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Cards</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Student</th>\n",
              "      <th>Married</th>\n",
              "      <th>Balance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.891</td>\n",
              "      <td>3606</td>\n",
              "      <td>283</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>11</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>106.025</td>\n",
              "      <td>6645</td>\n",
              "      <td>483</td>\n",
              "      <td>3</td>\n",
              "      <td>82</td>\n",
              "      <td>15</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104.593</td>\n",
              "      <td>7075</td>\n",
              "      <td>514</td>\n",
              "      <td>4</td>\n",
              "      <td>71</td>\n",
              "      <td>11</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>148.924</td>\n",
              "      <td>9504</td>\n",
              "      <td>681</td>\n",
              "      <td>3</td>\n",
              "      <td>36</td>\n",
              "      <td>11</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55.882</td>\n",
              "      <td>4897</td>\n",
              "      <td>357</td>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>16</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>12.096</td>\n",
              "      <td>4100</td>\n",
              "      <td>307</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>13</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>13.364</td>\n",
              "      <td>3838</td>\n",
              "      <td>296</td>\n",
              "      <td>5</td>\n",
              "      <td>65</td>\n",
              "      <td>17</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>57.872</td>\n",
              "      <td>4171</td>\n",
              "      <td>321</td>\n",
              "      <td>5</td>\n",
              "      <td>67</td>\n",
              "      <td>12</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>37.728</td>\n",
              "      <td>2525</td>\n",
              "      <td>192</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>13</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>18.701</td>\n",
              "      <td>5524</td>\n",
              "      <td>415</td>\n",
              "      <td>5</td>\n",
              "      <td>64</td>\n",
              "      <td>7</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows √ó 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Income  Limit  Rating  Cards  ...  Gender  Student Married Balance\n",
              "0     14.891   3606     283      2  ...    Male       No     Yes     333\n",
              "1    106.025   6645     483      3  ...  Female      Yes     Yes     903\n",
              "2    104.593   7075     514      4  ...    Male       No      No     580\n",
              "3    148.924   9504     681      3  ...  Female       No      No     964\n",
              "4     55.882   4897     357      2  ...    Male       No     Yes     331\n",
              "..       ...    ...     ...    ...  ...     ...      ...     ...     ...\n",
              "395   12.096   4100     307      3  ...    Male       No     Yes     560\n",
              "396   13.364   3838     296      5  ...    Male       No      No     480\n",
              "397   57.872   4171     321      5  ...  Female       No     Yes     138\n",
              "398   37.728   2525     192      1  ...    Male       No     Yes       0\n",
              "399   18.701   5524     415      5  ...  Female       No      No     966\n",
              "\n",
              "[400 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqn8_FG3yKHh"
      },
      "source": [
        "## Cleaning and reformat raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASIXtXLgsldO",
        "outputId": "3c36b79b-7fe7-4f30-bab7-b4138996f8c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Reformatting categorical data into numerical binary values\n",
        "datacopy = data # We use a copy and keep original import\n",
        "clean = datacopy.replace({'Male': 0, 'Female':1})\n",
        "clean = clean.replace({'No': 0, 'Yes': 1})\n",
        "clean"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Income</th>\n",
              "      <th>Limit</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Cards</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Student</th>\n",
              "      <th>Married</th>\n",
              "      <th>Balance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.891</td>\n",
              "      <td>3606</td>\n",
              "      <td>283</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>106.025</td>\n",
              "      <td>6645</td>\n",
              "      <td>483</td>\n",
              "      <td>3</td>\n",
              "      <td>82</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104.593</td>\n",
              "      <td>7075</td>\n",
              "      <td>514</td>\n",
              "      <td>4</td>\n",
              "      <td>71</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>148.924</td>\n",
              "      <td>9504</td>\n",
              "      <td>681</td>\n",
              "      <td>3</td>\n",
              "      <td>36</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55.882</td>\n",
              "      <td>4897</td>\n",
              "      <td>357</td>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>12.096</td>\n",
              "      <td>4100</td>\n",
              "      <td>307</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>13.364</td>\n",
              "      <td>3838</td>\n",
              "      <td>296</td>\n",
              "      <td>5</td>\n",
              "      <td>65</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>57.872</td>\n",
              "      <td>4171</td>\n",
              "      <td>321</td>\n",
              "      <td>5</td>\n",
              "      <td>67</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>37.728</td>\n",
              "      <td>2525</td>\n",
              "      <td>192</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>18.701</td>\n",
              "      <td>5524</td>\n",
              "      <td>415</td>\n",
              "      <td>5</td>\n",
              "      <td>64</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows √ó 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Income  Limit  Rating  Cards  ...  Gender  Student  Married  Balance\n",
              "0     14.891   3606     283      2  ...       0        0        1      333\n",
              "1    106.025   6645     483      3  ...       1        1        1      903\n",
              "2    104.593   7075     514      4  ...       0        0        0      580\n",
              "3    148.924   9504     681      3  ...       1        0        0      964\n",
              "4     55.882   4897     357      2  ...       0        0        1      331\n",
              "..       ...    ...     ...    ...  ...     ...      ...      ...      ...\n",
              "395   12.096   4100     307      3  ...       0        0        1      560\n",
              "396   13.364   3838     296      5  ...       0        0        0      480\n",
              "397   57.872   4171     321      5  ...       1        0        1      138\n",
              "398   37.728   2525     192      1  ...       0        0        1        0\n",
              "399   18.701   5524     415      5  ...       1        0        0      966\n",
              "\n",
              "[400 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayLY-VPOyTbi"
      },
      "source": [
        "## Initialize Variables for Training\n",
        "\n",
        "### Algorithms\n",
        "**Functions**\n",
        "* total_predict: computes predictions\n",
        "* residual: computes RSS\n",
        "* cost: computes min total cost\n",
        "* gradient: computes single gradient\n",
        "* gradient descent: computes total gradients under max iterations\n",
        "\n",
        "**Summary of Initialized Variables**\n",
        "\n",
        "* Recall our parameters for use in the coded algorithms below: X, Y, N, p, beta\n",
        "* X is our normalized training data centered and scaled to have unit standard deviation\n",
        "* Y is the true value data generated as ùëÅ-dimensional centered response vector ùê≤\n",
        "* N is the number of rows\n",
        "* p is the number of columns should be = (dimension of beta)\n",
        "* beta is our random initialized parameter vector\n",
        "\n",
        "Now we will introduce some additional assumptions for our fitting as follows:\n",
        "* tune is the Tuning Parameters Vector aka our lambda used in our Cost Function Equation\n",
        "* iter is set to 1000\n",
        "* alpha is initialized to 10^(-5) as suggested to act as proof of convergence within 1000 iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ1HfQZfrqyA",
        "outputId": "b5f02b36-9a7b-4c93-8e83-51d7655615ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "source": [
        "# Training Data, X, Y, N, p\n",
        "training_data = clean.iloc[:, :-1]                                # we only take the columns with 9 features we want to analyze\n",
        "X = (training_data - training_data.mean())/training_data.std()    # X_normalized\n",
        "Y_data = pd.DataFrame(clean.iloc[:, -1])                          # dependent variables; the true values y_i (i.e Credit Balance column)\n",
        "Y_centered = Y_data - Y_data.mean(axis=0)                         # Y_centered\n",
        "Y = pd.DataFrame(Y_centered)\n",
        "N = X.shape[0]                                                    # 400 rows\n",
        "p = X.shape[1]                                                    # 9 columns\n",
        "# randomized initialization beta vector\n",
        "random_initialization = np.random.uniform(low=-1.0, high=1.0, size=p)\n",
        "beta = pd.DataFrame(np.random.uniform(low=-1.0, high=1.0, size=p))\n",
        "# tuning parameter vector\n",
        "tune = [10**(-2), 10**(-1), 10**(0), 10, 10**(2), 10**(3), 10**(4)]\n",
        "max_iter = 1000\n",
        "alpha = 10**(-5)\n",
        "\n",
        "# Viewing all variables\n",
        "print('Training Data')\n",
        "print(training_data)\n",
        "print('')\n",
        "print('X')\n",
        "print(X)\n",
        "print('Y')\n",
        "print(Y)\n",
        "print('')\n",
        "print('N =', N, ', p =', p)\n",
        "print('')\n",
        "print('beta = ', beta)\n",
        "print('dimension:', beta.shape)\n",
        "print('')\n",
        "print('lambda tuning vector = ', tune)\n",
        "print('')\n",
        "print('alpha:', alpha)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data\n",
            "      Income  Limit  Rating  Cards  Age  Education  Gender  Student  Married\n",
            "0     14.891   3606     283      2   34         11       0        0        1\n",
            "1    106.025   6645     483      3   82         15       1        1        1\n",
            "2    104.593   7075     514      4   71         11       0        0        0\n",
            "3    148.924   9504     681      3   36         11       1        0        0\n",
            "4     55.882   4897     357      2   68         16       0        0        1\n",
            "..       ...    ...     ...    ...  ...        ...     ...      ...      ...\n",
            "395   12.096   4100     307      3   32         13       0        0        1\n",
            "396   13.364   3838     296      5   65         17       0        0        0\n",
            "397   57.872   4171     321      5   67         12       1        0        1\n",
            "398   37.728   2525     192      1   44         13       0        0        1\n",
            "399   18.701   5524     415      5   64          7       1        0        0\n",
            "\n",
            "[400 rows x 9 columns]\n",
            "\n",
            "X\n",
            "       Income     Limit    Rating  ...    Gender   Student   Married\n",
            "0   -0.860505 -0.489386 -0.464957  ... -1.034339 -0.332916  0.794400\n",
            "1    1.725276  0.827225  0.827667  ...  0.964384  2.996248  0.794400\n",
            "2    1.684646  1.013518  1.028023  ... -1.034339 -0.332916 -1.255665\n",
            "3    2.942467  2.065853  2.107363  ...  0.964384 -0.332916 -1.255665\n",
            "4    0.302549  0.069925  0.013314  ... -1.034339 -0.332916  0.794400\n",
            "..        ...       ...       ...  ...       ...       ...       ...\n",
            "395 -0.939809 -0.275366 -0.309842  ... -1.034339 -0.332916  0.794400\n",
            "396 -0.903832 -0.388875 -0.380936  ... -1.034339 -0.332916 -1.255665\n",
            "397  0.359012 -0.244606 -0.219358  ...  0.964384 -0.332916  0.794400\n",
            "398 -0.212542 -0.957716 -1.053100  ... -1.034339 -0.332916  0.794400\n",
            "399 -0.752403  0.341565  0.388175  ...  0.964384 -0.332916 -1.255665\n",
            "\n",
            "[400 rows x 9 columns]\n",
            "Y\n",
            "     Balance\n",
            "0   -187.015\n",
            "1    382.985\n",
            "2     59.985\n",
            "3    443.985\n",
            "4   -189.015\n",
            "..       ...\n",
            "395   39.985\n",
            "396  -40.015\n",
            "397 -382.015\n",
            "398 -520.015\n",
            "399  445.985\n",
            "\n",
            "[400 rows x 1 columns]\n",
            "\n",
            "N = 400 , p = 9\n",
            "\n",
            "beta =            0\n",
            "0  0.788917\n",
            "1  0.374703\n",
            "2 -0.342405\n",
            "3 -0.059052\n",
            "4 -0.707589\n",
            "5 -0.753808\n",
            "6  0.444057\n",
            "7  0.175548\n",
            "8 -0.613126\n",
            "dimension: (9, 1)\n",
            "\n",
            "lambda tuning vector =  [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
            "\n",
            "alpha: 1e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tyNPL8oyj-8"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZXyYqtuyrfi"
      },
      "source": [
        "## Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "786Bz3XXxRJR",
        "outputId": "3b7fb8d6-b546-475a-fb6d-f531d8220cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Prediction Function\n",
        "def total_predict(X, B):\n",
        "  '''\n",
        "    This function computes the dot product between the rows of design matrix and parameters column vector.\n",
        "    It uses the predict function to iterate through each row of design matrix.\n",
        "    :param X: training_data as pandas dataframe (i.e our Nxp design matrix)\n",
        "    :param B: is parameters_vector as pandas dataframe syntax (i.e p-dimensional B)\n",
        "    :return: predictions vector (i.e. dot product of X and beta parameters vector)\n",
        "  '''\n",
        "      # Corrective measure: Double check appropriate dimensions of dataframes\n",
        "  dim1 = X.shape[1]\n",
        "  dim2 = B.shape[0]\n",
        "  if  (dim1) == (dim2):\n",
        "    predictions = X.dot(B.to_numpy())\n",
        "    return (predictions)\n",
        "  else:\n",
        "    print('Cannot compute. Please check Dimensions!')\n",
        "    print('Dimensions of design matrix Nxp: ', X.shape)\n",
        "    print('Dimensions of Initialized Parameter Vector: (', len(B), 'x 1)')\n",
        "\n",
        "# Output\n",
        "yhat = total_predict(X, beta)\n",
        "print('Total predictions, yhat:')\n",
        "print(yhat)\n",
        "print('')\n",
        "print('yhat Transposed First few entries:')\n",
        "print((yhat.T).head(3))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total predictions, yhat:\n",
            "            0\n",
            "0   -0.186870\n",
            "1    0.398970\n",
            "2    1.526057\n",
            "3    4.909429\n",
            "4   -1.824202\n",
            "..        ...\n",
            "395 -0.665781\n",
            "396 -1.803241\n",
            "397 -0.053657\n",
            "398 -0.499326\n",
            "399  1.667169\n",
            "\n",
            "[400 rows x 1 columns]\n",
            "\n",
            "yhat Transposed First few entries:\n",
            "       0        1         2         3    ...       396       397       398       399\n",
            "0 -0.18687  0.39897  1.526057  4.909429  ... -1.803241 -0.053657 -0.499326  1.667169\n",
            "\n",
            "[1 rows x 400 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p86kFFgPytvb"
      },
      "source": [
        "## RSS Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zqfg3CsxjlB",
        "outputId": "40862b96-c408-4971-c69f-9d5c3e72c82c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# RSS Function\n",
        "def residual(Y, yhat):\n",
        "  ''' \n",
        "  :param Y: true values\n",
        "  :param yhat: predictions (i.e. dot product of X and parametric vector beta)\n",
        "  :return: residual sum of sqaures\n",
        "  '''\n",
        "  dim1 = Y.shape\n",
        "  dim2 = yhat.shape\n",
        "  print(\"Y and yhat Dimensions Check:\")\n",
        "  print(dim1, 'and', dim2)\n",
        "  rss = pd.DataFrame((Y.values - yhat.values)**2)\n",
        "  return rss\n",
        "\n",
        "# Output\n",
        "residual_result = residual(Y,yhat)\n",
        "print('rss:', residual_result)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y and yhat Dimensions Check:\n",
            "(400, 1) and (400, 1)\n",
            "rss:                  0\n",
            "0     34904.750080\n",
            "1    146372.070459\n",
            "2      3417.448002\n",
            "3    192787.357378\n",
            "4     35040.394995\n",
            "..             ...\n",
            "395    1652.486000\n",
            "396    1460.138553\n",
            "397  145894.467791\n",
            "398  269896.535752\n",
            "399  197418.335069\n",
            "\n",
            "[400 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O4uuHd5ywv7"
      },
      "source": [
        "## Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQSeooh8xp_E",
        "outputId": "b14c91cf-fc65-4a6c-8396-e73b49031835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Cost Function\n",
        "def cost(rss, tuning, b):\n",
        "  ''' \n",
        "  :param b: parametric_vector_B\n",
        "  :param rss: residual sum of squares \n",
        "  :param tuning: tuning_parameter_vector\n",
        "  :return: minimum cost computation\n",
        "  '''\n",
        "  # Checking pandas DataFrame dimensions\n",
        "  tuning = pd.DataFrame(tuning)\n",
        "  dim1, dim2, dim3 = rss.shape, tuning.shape, b.shape\n",
        "  print('')\n",
        "  print('rss Dimensions Check:', dim1)\n",
        "  print('tuning parameter vector Dimensions Check:', dim2)\n",
        "  print('b randomized vector Dimensions Check:', dim3)\n",
        "  print('')\n",
        "  # Cost Computation\n",
        "  tobesummed = []\n",
        "  for j in range(len(b)):\n",
        "    compute = tuning @ ((b.iloc[j])**2)\n",
        "    tobesummed.append(compute)\n",
        "  regularization = sum(tobesummed)\n",
        "  total_cost = rss.values + ((regularization).T).values\n",
        "  # Convert to pandas Dataframe syntax\n",
        "  return pd.DataFrame(total_cost)\n",
        "\n",
        "# Output\n",
        "rss1 = residual(Y, yhat)\n",
        "cost_result = cost(rss1, tune, beta)\n",
        "print('Cost Function Computation:')\n",
        "print(cost_result)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y and yhat Dimensions Check:\n",
            "(400, 1) and (400, 1)\n",
            "\n",
            "rss Dimensions Check: (400, 1)\n",
            "tuning parameter vector Dimensions Check: (7, 1)\n",
            "b randomized vector Dimensions Check: (9, 1)\n",
            "\n",
            "Cost Function Computation:\n",
            "                 0              1  ...              5              6\n",
            "0     34904.775643   34905.005716  ...   37461.106772   60468.317005\n",
            "1    146372.096023  146372.326095  ...  148928.427152  171935.637385\n",
            "2      3417.473565    3417.703638  ...    5973.804694   28981.014927\n",
            "3    192787.382942  192787.613014  ...  195343.714071  218350.924304\n",
            "4     35040.420558   35040.650630  ...   37596.751687   60603.961920\n",
            "..             ...            ...  ...            ...            ...\n",
            "395    1652.511564    1652.741636  ...    4208.842693   27216.052926\n",
            "396    1460.164116    1460.394189  ...    4016.495245   27023.705478\n",
            "397  145894.493355  145894.723427  ...  148450.824484  171458.034717\n",
            "398  269896.561316  269896.791388  ...  272452.892445  295460.102678\n",
            "399  197418.360632  197418.590704  ...  199974.691761  222981.901994\n",
            "\n",
            "[400 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGUReMDLyzEc"
      },
      "source": [
        "## Single Gradient Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEUVhxVmxx6Q",
        "outputId": "e62edae5-4821-4764-fabd-ead282f13be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Single Gradient Computation Function\n",
        "def gradient(X,Y, b, tuning_parameter_vector, alpha):\n",
        "  ''' \n",
        "  This function computes the gradient for each b_j in the parametric vector B.\n",
        "  :param X: training_data, this is our Nxp standardized matrix\n",
        "  :param Y: normalized predictions, our yhats\n",
        "  :param b: randomly initialized parametric vector, beta\n",
        "  :param tuning_parameter_vector: our lambdas vector of 7 values\n",
        "  :param alpha: starting point for learning\n",
        "\n",
        "  Note: This is just 1 iteration to simply test gradient computation.\n",
        "  '''\n",
        "  # Comment: I've broken down each step of the computation mathematically \n",
        "  # in order to ensure the syntax for the pandas Dataframe is correct and precise\n",
        "  for lambda_value in tuning_parameter_vector:\n",
        "    for k in range(len(b)):\n",
        "        step1 = Y.values -(X.dot(b.to_numpy()))\n",
        "        X_t = X.iloc[:, :k] # X column k transposed\n",
        "        step2 = (X_t).T  @ step1\n",
        "        step3 = lambda_value * b.iloc[k] - step2\n",
        "        step4 = 2 * lambda_value * step3\n",
        "        step5 = b.iloc[k] - step4\n",
        "        beta_update = step5\n",
        "  return beta_update\n",
        "\n",
        "# Output\n",
        "print('Single gradient function computation (check):')\n",
        "singlegradient = gradient(X,Y, beta, tune, alpha)\n",
        "print(singlegradient)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single gradient function computation (check):\n",
            "                      0\n",
            "Income     1.818221e+09\n",
            "Limit      3.279393e+09\n",
            "Rating     3.286506e+09\n",
            "Cards      4.405286e+08\n",
            "Age        1.335926e+08\n",
            "Education  9.937858e+07\n",
            "Gender     1.978962e+08\n",
            "Student    1.071097e+09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvXKVFA2zbLS"
      },
      "source": [
        "## Gradient Descent Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olhI_-LnzekH",
        "outputId": "6ab770d9-cc2b-4f19-dacb-3748fcc10c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Gradient Descent Function\n",
        "def gd(X,Y,tune,alpha,max_iter):\n",
        "  '''\n",
        "  :param X: our standardized Nxp design matrix, <class 'pandas.core.frame.DataFrame>\n",
        "  :param Y: our N-dimensional centered y\n",
        "  :param beta: our randomply initialized parametric vector B\n",
        "  :param max_iter: max iterations alloted for convergence\n",
        "  :param alpha: proof of when convergence occurs (i.e. 2*alpha*lambda <1)\n",
        "  :param L: lambda value in tuning parameter vector\n",
        "  :return beta_update, cost: total gradient calculation and cost computation\n",
        "\n",
        "  This function is used for 'training' phase/step.\n",
        "  '''\n",
        "  # Computations\n",
        "  b = pd.DataFrame(data=np.random.uniform(-1, 1, X.shape[1]))\n",
        "  XB = pd.DataFrame((X.values).dot(b.values))\n",
        "  Y_minus_XB = pd.DataFrame(Y.values - XB.values)\n",
        "  X_T_dotprod_Y_minus_XB = (X.T).dot(Y_minus_XB)\n",
        "\n",
        "  # Change to dataframe syntax for computations\n",
        "  tuning = pd.DataFrame(tune)\n",
        "  Lb = tuning.dot(b.T)\n",
        "  # Making pretty dataframe for lambabeta - for faster computations\n",
        "  d = pd.Series(tune)\n",
        "  lambda_beta_df = (Lb.T).rename(columns = d, inplace = False)\n",
        "  # We will use this dataframe to plot a graph later\n",
        "\n",
        "  # Iterate for every column in lambda_beta dataframe and subtract XB column\n",
        "  for i in lambda_beta_df.columns:\n",
        "    compute = lambda_beta_df[i].values - (X_T_dotprod_Y_minus_XB.iloc[:,0].values)\n",
        "\n",
        "  # Iterate for 1000 iterations - this yields convergence by given assumption\n",
        "  for iteration in range(max_iter):\n",
        "    b_temp = (2*alpha)*(pd.DataFrame(compute))\n",
        "    b_update = b - b_temp\n",
        "  return b_update, lambda_beta_df # return new updated beta vector\n",
        "\n",
        "# Output\n",
        "gd_computation = (gd(X, Y, tune, alpha, 1000)[0])\n",
        "to_plot = (gd(X, Y, tune, alpha, 1000)[1])\n",
        "print('For gradient descent:')\n",
        "print(gd_computation)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For gradient descent:\n",
            "          0\n",
            "0  1.587045\n",
            "1  2.522692\n",
            "2  3.890038\n",
            "3  0.746434\n",
            "4 -0.220751\n",
            "5  0.128189\n",
            "6 -0.505701\n",
            "7  0.929778\n",
            "8  0.762069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz1v1j3TPOUD"
      },
      "source": [
        "## Deliverable 1\n",
        "\n",
        "Illustrate the effect of the tuning parameter on the inferred ridge regression coefficients by generating a plot of nine lines (one for each of the ùëù = 9 features), with the ùë¶-axis as $ùõΩ_ùëó = 1,2, ... ,9$ , and the ùë•-axis the corresponding log-scaled tuning parameter value $\\log_{10}(ùúÜ)$ that generated the particular $\\hat{ùõΩ}_j$. Label both axes. Without the log scaling of the tuning parameter, the plot will look distorted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE9DRHiXPQ7s",
        "outputId": "cd810904-2b6b-4165-c486-18750503e039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "d1 = pd.DataFrame(to_plot.T)\n",
        "# Adding labels for corresponding b_j values in beta vector computed in dataframe\n",
        "beta = pd.Series(['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9'])\n",
        "d1 = (d1).rename(columns = beta, inplace = False)\n",
        "# View our dataframe which we will use to plot for Deliverable 1\n",
        "d1\n",
        "\n",
        "# Notes for Plotting\n",
        "# Each column for b_j's in the d1 dataframe will be the plotted y-axis points\n",
        "# And the x-axis will consist of the lambda values on the log scale (first column of dataframe)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>b1</th>\n",
              "      <th>b2</th>\n",
              "      <th>b3</th>\n",
              "      <th>b4</th>\n",
              "      <th>b5</th>\n",
              "      <th>b6</th>\n",
              "      <th>b7</th>\n",
              "      <th>b8</th>\n",
              "      <th>b9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.01</th>\n",
              "      <td>-0.009564</td>\n",
              "      <td>0.004572</td>\n",
              "      <td>0.002080</td>\n",
              "      <td>0.003576</td>\n",
              "      <td>0.008227</td>\n",
              "      <td>-0.006119</td>\n",
              "      <td>-0.005607</td>\n",
              "      <td>-0.008346</td>\n",
              "      <td>-0.002855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.10</th>\n",
              "      <td>-0.095641</td>\n",
              "      <td>0.045722</td>\n",
              "      <td>0.020798</td>\n",
              "      <td>0.035764</td>\n",
              "      <td>0.082268</td>\n",
              "      <td>-0.061185</td>\n",
              "      <td>-0.056072</td>\n",
              "      <td>-0.083455</td>\n",
              "      <td>-0.028545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.00</th>\n",
              "      <td>-0.956413</td>\n",
              "      <td>0.457224</td>\n",
              "      <td>0.207979</td>\n",
              "      <td>0.357640</td>\n",
              "      <td>0.822679</td>\n",
              "      <td>-0.611854</td>\n",
              "      <td>-0.560718</td>\n",
              "      <td>-0.834554</td>\n",
              "      <td>-0.285452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.00</th>\n",
              "      <td>-9.564132</td>\n",
              "      <td>4.572236</td>\n",
              "      <td>2.079788</td>\n",
              "      <td>3.576396</td>\n",
              "      <td>8.226792</td>\n",
              "      <td>-6.118544</td>\n",
              "      <td>-5.607181</td>\n",
              "      <td>-8.345542</td>\n",
              "      <td>-2.854518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100.00</th>\n",
              "      <td>-95.641325</td>\n",
              "      <td>45.722357</td>\n",
              "      <td>20.797877</td>\n",
              "      <td>35.763959</td>\n",
              "      <td>82.267915</td>\n",
              "      <td>-61.185443</td>\n",
              "      <td>-56.071811</td>\n",
              "      <td>-83.455419</td>\n",
              "      <td>-28.545178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000.00</th>\n",
              "      <td>-956.413248</td>\n",
              "      <td>457.223572</td>\n",
              "      <td>207.978773</td>\n",
              "      <td>357.639594</td>\n",
              "      <td>822.679150</td>\n",
              "      <td>-611.854429</td>\n",
              "      <td>-560.718108</td>\n",
              "      <td>-834.554188</td>\n",
              "      <td>-285.451780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000.00</th>\n",
              "      <td>-9564.132478</td>\n",
              "      <td>4572.235719</td>\n",
              "      <td>2079.787728</td>\n",
              "      <td>3576.395942</td>\n",
              "      <td>8226.791501</td>\n",
              "      <td>-6118.544289</td>\n",
              "      <td>-5607.181084</td>\n",
              "      <td>-8345.541878</td>\n",
              "      <td>-2854.517796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   b1           b2  ...           b8           b9\n",
              "0.01        -0.009564     0.004572  ...    -0.008346    -0.002855\n",
              "0.10        -0.095641     0.045722  ...    -0.083455    -0.028545\n",
              "1.00        -0.956413     0.457224  ...    -0.834554    -0.285452\n",
              "10.00       -9.564132     4.572236  ...    -8.345542    -2.854518\n",
              "100.00     -95.641325    45.722357  ...   -83.455419   -28.545178\n",
              "1000.00   -956.413248   457.223572  ...  -834.554188  -285.451780\n",
              "10000.00 -9564.132478  4572.235719  ... -8345.541878 -2854.517796\n",
              "\n",
              "[7 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YwLKBgwbxyE",
        "outputId": "59f586a2-fed3-40b3-9938-1f8755019e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "# Initialize figure\n",
        "fig = plt.figure()\n",
        "plt.title('Ridge Regression Fit')\n",
        "\n",
        "# Plotting\n",
        "for i in range(len(d1.columns)):\n",
        "  # tuning parameter lambda and lambda_beta column values\n",
        "  plt.plot(tune, d1.iloc[:, i])\n",
        "\n",
        "# Axes\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Tuning Parameter Values')\n",
        "plt.ylabel('Features')\n",
        "\n",
        "plt.show()\n",
        "fig.savefig('Deliverable1.jpg')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEaCAYAAADDgSq4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5wV1dnA8d9z793eG8vSXOoioICuCFHEglIsYMEejSlqjDF5oxhNXlM1iSYmxhTzaoI1KNhREAQNRFSQItKkLE3KVnbZXm553j/ugBfYZRfYchef7+cznzv3zJkzz6x+7sOcmXNGVBVjjDGmLbg6OgBjjDEnLksyxhhj2owlGWOMMW3Gkowxxpg2Y0nGGGNMm7EkY4wxps1YkjEnLBH5h4g8cITtKiL92jOmcCcivUSkSkTcJ+LxTPsTGydjOisR2Q5kAn6gCpgL3KmqVS3cX4H+qprXynEtBEYCPqAO+C/wPVXNb83jdDbO37sG2P+j41PV5EPqLAReUNV/tnN4po3YlYzp7C5V1XhgGDAcuL+D49nvTieufkA88IfWPoCIeFq7zXYwVFXjnSW5+eqms7MkY04IqloAzCOYbAAQkWdE5MGQ71NFJF9E9ojIN0P3F5E0EXlLRCpEZJmIPCgii0O2DxSR+SJSKiIbReTqFsa1D3jjkLiabKsFcaiIfE9ENgObnbJLRGSViOwTkY9E5NSQ+j8Wkd0iUukc6wKnfISILHeOUygif3TKs51jeJzv3URklhNrnoh8J6TtX4jITBF5zml/nYjktuTvEtLGgeOJyEPAaOCvThfaX4+mLROeLMmYE4KI9AAmAI12fYnIeOAe4EKgPzD2kCp/A6qBrsDNzrJ/3zhgPjAd6AJcC/xdRAa1IK404Ir9cbWgrSbjCDEZOBMYJCLDgWnAbUAa8H/ALBGJEpEc4E7gDFVNAMYB2502/gz8WVUTgb7AzCZO4SVgF9ANuAr4jYicH7L9MqdOMjALOObEoKo/BT7AuQpU1TuPtS0TPizJmM7uDRGpBHYCRcDPm6h3NfC0qq5V1WrgF/s3ODedrwR+rqo1qroeeDZk30uA7ar6tKr6VPVT4FVgyhHielxEyoESIB34fnNttSCO/X6rqqWqWgvcCvyfqi5VVb+qPgvUE7wn5AeiCCajCFXdrqpbnDa8QD8RSVfVKlVdcuhBRKQncBbwY1WtU9VVwD+Bm0KqLVbVOarqB54Hhh7hbwKw0rni2icijzdT15wALMmYzm6y86/0c4GBBH/QG9ONYCLab0fIegbgOWR76PpJwJkhP477gBsIXm005S5VTQJOBVKAHi1oq7k4mort7kPa6wl0cx5o+CHBhFokIi+JSDdnv28BA4ANTrfcJY0cpxtQqqqVIWU7gO4h3wtC1muA6GbuFZ2mqsnOctcR6pkThCUZc0JQ1UXAMzR9gz2f4I/vfr1C1osJPgnWI6QstO5OYFHIj2Oy053z3RbEtQZ4EPibiEgzbTUXx4FmD4ntoUPai1XVF53jT1fVswkmIwUedso3q+p1BLvsHgZecbryQu0BUkUkIaSsF7C7ufM+Dva46wnGkow5kTwGXCgijXXZzAS+ISKDRCSWkG41p6vnNeAXIhIrIgM5uEvobWCAiHxdRCKc5QwRObmFcT1L8FHry47UVgviaMxTwO0icqYExYnIxSKSICI5InK+iEQRfJS6FggAiMiNIpKhqgFgn9NWILRhVd0JfAT8VkSinQcKvgW80MLzPhaFQJ82bN+0M0sy5oShqsXAc8DPGtn2DsEk9D7Bm/DvH1LlTiCJYPfP88CLBO9t4HQXXUTwJv0ep87DBO93tCSuBoI32h9oQVtNxtFE28uB7xC84V7mnNs3nM1RwO8I3hcqIHjVsv8R7/HAOhGpcmK71rnHc6jrgGwn1tcJ3i9a0JLzPkZ/Bq4SkTK7Z3NisMGYxjRCRB4GuqpqY093feXiMOZY2ZWMMRwYu3Kq0+U0gmC30Otf1TiMaS2dccSwMW0hgWDXVDeC9wUeBd78CsdhTKuw7jJjjDFtxrrLjDHGtBlLMsYYY9qM3ZM5RHp6umZnZ3d0GMYY06msWLGiRFUzDi23JHOI7Oxsli9f3tFhGGNMpyIiOxort+4yY4wxbcaSjDHGmDZjScYYY0ybsSRjjDGmzViSMcYY02YsyRhjjGkzlmSMMeYrTgPKhiX5+P2B5isfJUsyxhjzFff5R/m898znbFtV0uptW5IxxpivsNrKBj56PY9u/ZPpe9phA/aPmyUZY4z5CvvotTy8tX7GXJeDiLR6+5ZkjDHmK2r3pjI2fFzAsAt7kdotrk2OYUnGGGO+gvy+AIumbyQhLZrci7Pb7DhhmWREJEdEVoUsFSLyQxH5hYjsDimfGLLP/SKSJyIbRWRcSPl4pyxPRO7rmDMyxpjwsmrBF5QV1HDOtQOIiHS32XHCchZmVd0IDAMQETewm+B7zm8B/qSqfwitLyKDgGuBwQRfW7tARAY4m/8GXAjsApaJyCxVXd8uJ2KMMWGovLiWZbO302d4BtmnpLfpscIyyRziAmCLqu44wk2pScBLqloPbBORPGCEsy1PVbcCiMhLTl1LMsaYryRV5YMZm3C5hNFX92/z44Vld9khrgVeDPl+p4isFpFpIpLilHUHdobU2eWUNVVujDFfSVtXFbNj7V5GXNqb+JToNj9eWCcZEYkELgNedoqeAPoS7ErLBx5tpePcKiLLRWR5cXFxazRpjDFhp6HOxwczNpPWI55Tz+vRLscM6yQDTABWqmohgKoWqqpfVQPAU3zZJbYb6BmyXw+nrKnyg6jqk6qaq6q5GRmtPxjJGGPCwSdvbaO6vJ5zb8jB5W6fn/9wTzLXEdJVJiJZIdsuB9Y667OAa0UkSkR6A/2BT4BlQH8R6e1cFV3r1DXGmK+U4i8qWf3+Tgaf3Y2uvZPa7bhhe+NfROIIPhV2W0jxIyIyDFBg+/5tqrpORGYSvKHvA76nqn6nnTuBeYAbmKaq69rtJIwxJgwEAsrC6RuJjo9g5OS+7XrssE0yqloNpB1S9vUj1H8IeKiR8jnAnFYP0BhjOon1i/dQtL2CsbcMIjouol2PHe7dZcYYY45DTUUDS97YQvecZAaMyGz341uSMcaYE9iHr27G29B2E2A2x5KMMcacoHZtKGXT0kJOu+gkUrq2zQSYzbEkY4wxJyC/N8CiFzeRmBHD6eNP6rA4LMkYY8wJaOW7O9hXWMOYawfgacMJMJtjScYYY04w+4pqWPHODvqd3oVeg9Oa36ENWZIxxpgTiKry35c24fIIZ09p+wkwm2NJxhhjTiB5K4rYub6UkZP6EJcc1dHhWJIxxpgTRX2tj8UvbyajVwJDxrTPBJjNsSRjjDEniKWztlJT0RCcANPV/mNiGmNJxhhjTgBFOypYu3AXp4zpQZeTEjs6nAMsyRhjTCcXCCgL/72RmIRIzpzUp6PDOYglGWOM6eTWLtpN8ReVnD2lP1Ex4TXvsSUZY4zpxKrL61n65hZ6npxCv9wuHR3OYSzJGGNMJ/bhy5vx+5Rzru2YCTCbY0nGGGM6qS/W72Xz8iJOn3ASyZmxHR1OoyzJGGNMJ+Rr8LPoxU0kZ8Zy2kUdNwFmcyzJGGNMJ7Ri3g4qims557oBuCPC96c8fCMzxhjTqH2FNayct4P+Z2TSc2BqR4dzRGGbZERku4isEZFVIrLcKUsVkfkistn5THHKRUQeF5E8EVktIqeFtHOzU3+ziNzcUedjjDGtQVVZ9OJGPBFuzrqqX0eH06ywTTKO81R1mKrmOt/vA95T1f7Ae853gAlAf2e5FXgCgkkJ+DlwJjAC+Pn+xGSMMZ3R5mWF7NpQxqjJfYhL6vgJMJsT7knmUJOAZ531Z4HJIeXPadASIFlEsoBxwHxVLVXVMmA+ML69gzbGmNZQV+1l8cub6ZKdyKDR3Ts6nBYJ5ySjwLsiskJEbnXKMlU131kvADKd9e7AzpB9dzllTZUfRERuFZHlIrK8uLi4Nc/BGGNazdI3t1JX5eXc68NnAszmhNf8Awc7W1V3i0gXYL6IbAjdqKoqItoaB1LVJ4EnAXJzc1ulTWOMaU0F28pZ+8Fuhp7Xk4xeCR0dTouF7ZWMqu52PouA1wneUyl0usFwPouc6ruBniG793DKmio3xphOI+APsGj6RuKSohhxWe+ODueohGWSEZE4EUnYvw5cBKwFZgH7nxC7GXjTWZ8F3OQ8ZTYSKHe61eYBF4lIinPD/yKnzBhjOo01C3dTsrOKs6f0JzK6jTqgtG06ccK1uywTeN2Zh8cDTFfVuSKyDJgpIt8CdgBXO/XnABOBPKAGuAVAVUtF5NfAMqfer1S1tP1Owxhjjk9VWT1LZ22l1+A0+p6W0TYHKd0Gr98Olz8Bqa37qoCwTDKquhUY2kj5XuCCRsoV+F4TbU0DprV2jMYY0x4Wv7yJQEA559oBbTMBZv5n8MJVEPBCTWmrJ5mw7C4zxhgD29eUsGVlMbkTs0nKiGn9A2xdCE9fDO5I+OY86JHb7C5Hy5KMMcaEIW+Dnw9mbCKlayzDL+zV+gdY80rwCia5J3x7PmTktP4xsCRjjDFhacWc7VSU1DHm+hzcnlb+qV7yBLz6LehxBtwyBxK7tW77IcLynowxxnyVleZX8+n8Lxg4sivdB7TiTFiqsOAX8OFjMPASuPKfENEG3XAhLMkYY0wYUVUWTd9IRJSbr13ZihNg+r0w6/vw2Ytw+i1w8aPgcrde+02wJGOMMWFk49IC9mzex7k35BCTENk6jTZUw8ybIW8+nPsTGHMvtNOrmi3JGGNMmKir9vLhK3l07ZPIoLNa6T5J9V6YPgX2fAqXPAa5t7ROuy1kScYYY8LEx69vob7Gx5jrByKtMQFm2Q544Qoo3wVXPw8nX3L8bR4lSzLGGBMG8reUs37xHoZd2Iv0HvHH32DBGnjhSvDVwdffgJNGHX+bx8AeYTbGmA7m9wdYNH0D8SlRnHFx9vE3uO0DeHoiuDzBQZbNJJiGnTvZ+d078BYVHbHesbAkY4wxHWz1+7vYu7ua0dcMOP4JMNe9EewiS8iCb70LXU5usqqqsu+119k2aTI1y5fTsHXr8R27EdZdZowxHaiytI5P3t5G9qnp9Bl2nBNgfvIUzJkKPUfAdS9BbGqTVX1lZRT84pdUzptH7Bln0O3h3xHRrfUHZVqSMcaYDvTBjE2gyuhr+h97I6rw/oPwwR8gZyJcNe2IgyyrP/qIPffdj6+sjC733E3qLbcg7rYZM2NJxhhjOsi2z4rZ9lkJoy7vS2LaMY689/vg7R/Apy/AaTfBxX8Cd+M/7YH6eor/+CdKn32WyL596f2PJ4geNOg4zqB5lmSMMaYDeOv9/HfGJlK7xTF0bM/md2hMQw28cgtsmgvn3Avn/aTJQZZ1GzexZ+pU6jdtIuWGG+hyz924Ytp2ShmwJGOMMR1i2extVJXWc/k9g3G7j+EZrJpSmH4N7FoWnCLmjG83Wk0DAUqfe47iR/+IKymJnk/+H/HnnHOc0becJRljjGlne3dX8dmCnZx8Vhbd+iUffQP7dgafICvbAVc/B4Mua7Sat7CQ/Pvvp/qjj4k//3yyHvw1ntSmHwZoC5ZkjDGmHWlAWfTiRiJjPHzt8mOYALNwXXCQZUMNfP01yD670WoV896l4Gc/I9DQQNdf/ZLkKVPa5s2azbAkY4wx7ejzj/PJzyvn/JtOJjo+4uh23v4hvHgdRMbCN9+BzMGHVfFXVVP40EOUv/460aecQrdHHiaqd+9Wiv7ohd1gTBHpKSL/EZH1IrJORH7glP9CRHaLyCpnmRiyz/0ikiciG0VkXEj5eKcsT0Tu64jzMcaY/WqrGvjotTyy+iUxcFTXo9v587fg+cshvktwkGUjCaZm5adsu/xyyt98k7Tv3k729H93aIKB8LyS8QF3q+pKEUkAVojIfGfbn1T1D6GVRWQQcC0wGOgGLBCRAc7mvwEXAruAZSIyS1XXt8tZGGPMIT56bQveWj9jrs85uq6rZf+COfdA99Ph+pmHDbJUr5eSJ/5ByT/+QURWFie98Dyxp53WytEfm7BLMqqaD+Q765Ui8jnQ/Qi7TAJeUtV6YJuI5AEjnG15qroVQERecupakjHGtLs9m8vY8FE+p407ibRuLZwAUxUW/hYWPQz9x8GUpyEy7qAqDTt2sPvee6n7bDVJkyaR+cD/4o5vhQk2W0nYdZeFEpFsYDiw1Cm6U0RWi8g0Edn/TtLuwM6Q3XY5ZU2VN3acW0VkuYgsLy4ubsUzMMYY8PsCLJy+iYS0aHJbOgGm3wdv/zCYYIbdCNf++6AEo6qUvfwyWy+/gobtO+j+pz/S7eHfhVWCgTBOMiISD7wK/FBVK4AngL7AMIJXOo+21rFU9UlVzVXV3IyM45w7yBhjDvHZezspy6/mnGsHEBHZgulbvLUw8yZY8QyMvhsm/RXcXz4k4CsrY9f3v0/BAz8jZuip9HnzDRInTGi7EzgOYdddBiAiEQQTzL9V9TUAVS0M2f4U8LbzdTcQOly2h1PGEcqNMaZdVJTUsuztbfQZnkH2KenN71BTGnyCbOdSmPAInHnbQZurPviAPT/5CYF95XT58Y9JvfkmxBW21wvhl2QkeDfsX8DnqvrHkPIs534NwOXAWmd9FjBdRP5I8MZ/f+ATQID+ItKbYHK5Fri+fc7CGGOCXVr/nbEJcQmjr27BBJjlu4JjYEq3Bie5HHLFgU2BujqK/vAoZS+8QFT/fnR76imiBw5stVjL6spIjkpu9bE0YZdkgLOArwNrRGSVU/YT4DoRGQYosB24DUBV14nITII39H3A91TVDyAidwLzADcwTVXXteeJGGO+2ratKmHHmr2cdVU/4lOij1y5aENwFH9dBdz4KvT+cuqXus8/Z/fUqTTkbSHlpq/T5e67cUVFHXd8qsrKopXM2DiD+Tvm89SFT5HbNfe42w0VdklGVRcTvAo51Jwj7PMQ8FAj5XOOtJ8xxrSVhjofH8zcRFqPeE49r8eRK3+xJDgPmScKbpkDWacCzrxjTz9D0WOP4UlOpuc//0n82Wcdd2xVDVW8tfUtZm6cSd6+PBIiErgm5xq6xh3l2J0WCLskY4wxJ4JP3t5G1b56xn1nCK4jTYC5YU5wJuXE7sFpYlKyAfDm57PnvvupWbqUhAvH0vVXv8KTktJ0Oy2woXQDMzbOYPbW2dT6ahmUNohffu2XjM8eT2xE7HG13RRLMsYY08pKdlWy+v1dDD67G137JDVdccWzwceUs4bBDS9DXPDBgIo5c8j/xS9Rn4+shx4k6YorjvleSZ2vjnd3vMuMjTNYXbyaaHc043uP55qcaxiSPuSY2jwalmSMMaYVaUBZ+O+NRMd5GDm5bxOVFP77e/jPQ9BvLEx5FqLi8VdWUvjgg5S/OYuYoUPp9vtHiOzV65ji2FGxg5c3vswbW96gvL6c7MRs7j3jXi7rexlJUUdIfK3MkowxxrSi9R/uoXBbBWNvGUR0XCMTYAb8MGcqLP8XDL0OLvsLuCOoWb6cPff+GG9hIel33kn67bchnqP7ifYFfCzcuZCZG2fycf7HeMTDeb3O45qcaxjRdYTNwmyMMZ1ZTUUDH7++he45yQwYkXl4BW8dvPbt4GSXZ/0Axv4S9Xopfvwx9j71FBE9epD97xeIGTbsqI5bWF3Iq5tf5dVNr1JUW0TXuK7cOexOruh/BRmxHTvA3JKMMca0ko9ezcNb72fMdY1MgFm7D166HnZ8CON+C6PuoH7rNvZMnUrdunUkXXUlmffdjzs+rvHGDxHQAEvylzBz40wW7lxIQAN8rfvX+N8B/8voHqPxuMLj5z08ojDGmE5u18YyNi4tIHdiNildD0kUFXvghaugZBNc+S90yJXse+klCn/3MK6oKLo//mcSL7qoRcfZV7ePN7e8ycubXmZHxQ5SolK4afBNTBkwhZ4JPZtvoJ1ZkjHGmOPk9wZYNH0jienRnD7+pIM3Fm8KDrKsLYMbXsaXfCr5372DqoULiTvrLLJ+8xsiMrscsX1VZXXJamZunMncbXNpCDQwvMtwbh96OxeddBGR7sg2PLvjY0nGGGOO06fzv2BfYQ2XfH8ontAJMHcug+lTwOWBb8ymctM+8m+aRKCyksyf/ISUG2844rxjNd4aZm+bzcyNM9lQuoFYTyyX97+cKQOmkJOa0w5ndvwsyRhjzHEoL65h+Tvb6Xd6F04anPblhk3zYObNkNCVwJTpFD71MvtefImonBy6PT2N6AEDmmwzryyPGRtn8NbWt6j2VjMgZQAPjHyAi/tcTFxEy+7ZhIsWJRkR6QvsUtV6ETkXOBV4TlX3tWVwxhgTzlSV/760CZdbOHtKyASYn74As+6CrqdQe/pD7Pn2VBq2biX1llvI+J8f4oo8vHurwd/Agh0LmLFxBiuLVhLhimBc9jiuybmGoRlDO+Tx49bQ0iuZV4FcEekHPAm8CUwHJrZVYMYYE+62rCzmi3WljL6mP3HJUcFBlh88Cu//Gs0+l701F1L8je/iSUuj19PTiBs16rA2dlXu4uVNL/NG3huU1pXSM6EnPzr9R0zuN5mU6OObRiYctDTJBFTVJyKXA39R1b+IyKdtGZgxxoQLb4OffQU1lOZXU5ZfTZmzXl5cS0avBIaM6REcZDn3PvjkSbw9LmXPAqhZ/jcSJown6+c/x52cfKA9f8DPB7s/YMbGGXy4+0NEhDE9xnBNzjWM6jYKl4Tv+2GOVkuTjFdErgNuBi51yhoZymqMMZ1Xfa2PsvzqYDIpqDmwXllaF3zJCCAuIblLDKlZcfQdnsHgc7rjCjTAa7fC+jcoj7iMgn9sAFWyfvdbkiZNOtDVVVJbwmubX+OVTa+QX51PRkwGtw29jSv7X9kmMyCHg5YmmVuA24GHVHWb8yKw59suLGOMaRuqSm2ll7KC4FVJqZNMyvKrqS5vOFDP7XGRnBlL196JnPy1LFK6xpGaFUdSlxjcnpArjbpyeOEG/JsWU7B7DBVLlxNz2ml0e+RhInv0QFVZVrCMGRtn8N6O9/CpjzOzzmTqGVM5t+e5RLhO7H+vtyjJqOp6Efkx0Mv5vg14uC0DM8aY46GqVJXVO8mkhlInqZTl11BX7T1QLyLKTUrXWHqenEpKVlxw6RpLYnoMLlczN9srC+CFq6hem8eeVTn4yreR8cMfkPbtb1MZqOHlz//NzI0z2Vq+lcTIRK47+TqmDJhC76TebXz24aOlT5ddCvwBiAR6O2+o/JWqXtaWwRljTHMCAaVyby2l+V9ekZTmV1NWWIO3zn+gXlSch9SsOPqclkFq1zhSsmJJ6RpHfErUwU9uqUJ9BZTugeoiqCqC6mLnswiqig+U674CitfEs3d9KpG9Usj+xz/Z2s3FXz75Ne9se4daXy2npJ/Cr8/6NeOzxxPtaebtmCeglnaX/QIYASwEUNVVItKnjWIyxpjD+H0ByotqnfslX3Z17Suowe8LHKgXlxRJSlYcA0dlkdo1NnhlkhlLTEQ1Ul3iJIj1UFkM+QcnDq0owl9Wgr+mgUCDC//+pd6F3+vGH4jB74/B7/Xgb4jCV9EdX0Ud8VMuZ8XVp/K/O37D2pVrifHEMLH3RK7OuZpBaYM68K/W8Vp8419Vyw95TjvQVOVwIiLjgT8DbuCfqvq7Dg7JGHMEBz3J5XR1lRVUs6+oFg3ogXqJadGkdImk50kxpCTWkhpbRkpkEVHeArS8AH9JAf4tRfj3leIvr6C81v9l0mhwfZlEfJH4G9z46yFQHwCaeGxYBFdCApKUAAnxBLrE4YuPZvkpMTyZ+B8qV86iT1If7htxH5f2vZTEyMT2+YOFuZYmmXUicj3gFpH+wF3AR20XVusQETfwN+BCYBewTERmqer6jo3MGNPYk1xl+dVUhD7JJUpiXB3JkWX0TCokwbuTxNptxFVuRYrK8a8ieJXR4KKmwUWFkzjwHXov5csffBXBFxdJQ3wUDfFR1MVGUBvrpibGRXWMUBEDlVFKeZSffVE+SiMb2BvZQKm7joCrBqgBCg+053F5GNttLFfnXE1uZm6nHTTZVlqaZL4P/BSoJzgIcx7wYFsF1YpGAHmquhVARF4CJgGWZEyno6qoQsAfIOBXNKDBdV8A9QcI+P34vV4CPh/qDa6rz0/AFyDg8xLYv+71Bev6/AT8wTK/z4/6Fb/fKfNr8DNAcLtf0UDwuIFAcFE/znrwUxUCAdAAThmoSvC7SnC7873eG0m9/8t3yot6ifYWElu3hx41BcRVFpBQUUh8VTEu9R/0d6h3Fp8rjupYoSpaqIpWKpKgKhqqYgiWxTT+vS4KVPxADTEeJdoNMR4P0Z4oYjwxRHuiifHEEOOJIcMTQ0939EHl0Z5oYj2xB74PSR9Cekx6u/6/0Jk0m2Scq4HZqnoewUTTmXQHdoZ83wWc2RYHevWpK4ntsbEtmjbH7Tj+ZanHuu8R9tOmNzW7L8EfaxCnHXHWnX1UvtxfG9l2aL3Q7y4J7uqRg7c3so8ciEFwKbg0JB7dfywQPfh7sAzwgbvKh2dfJe6qKvz1VdQr1ERBZaSQnypUuYTayAjq42LxxcfgS4gmkBCLxsdDYjyeuDhiImIP+vGP88SS5o4mJiKGaHfjSWH/Z5Q76oQa9Biumk0yquoXkYCIJKlqeXsE1d5E5FbgVoBex/g+bX9lEnXF2a0YlWkdh/+iN/sb75BDaurBG1u032HHajZnHSE6cbbL/r6k4KeKHlx+WJ3gd6c2Is52p46E7Cch+0jIMfbXEfRAHKHbg+1+Gb8coW0F3C4/uL34BfZfp3gIdmodfCejAbcbPJ4IPB7B43bj9rjxeDx43BF4PNG4PQl4PPF43MFPtycejycBj9v59MTjcsVYN1YHaWl3WRWwRkTmA9X7C1X1rjaJqvXsBkLf4tPDKTuIqj5JcE42cnNzW/obdJCrfzTtWHYzpt34A4rXHwh++gLU+3w0eP00eH34/H4afD4afH683gBev4+GBh9enxev14fX68XX4MXn9eP3efF7/fh9Pnw+PwGfz+la8zvdd8F19QeCXWyB4KeqHwJKQJVAQx3qr8EdUYNENODxeC1OWioAACAASURBVHG7vUS7/SS6XSS4hFiPEu0OEOX2g6cOf2Qt9ZG1BCL3oRH1qKeOgNQS0Npmz13EjdsdH0xGnoSD1vcnI7cn/qDE5D4kUbndCbjdUe3wX+rE0tIk85qzdDbLgP7ODAW7gWuB6zs2JGM6htsluF3Ou06iIDjsreOoKjtLa1i1NZ8N23azs6CQ6rJiYr2VJLrqcbu+/PeeR4UEfxRJgRjSNIl0SSYlEEccUSABAu46GiIr8MXUoPENkOjDnaS4k4FYHxpZS8Bdi0+r8fkq8fuqaGgopqZmGz5fFX5/JYFAQ9PBOkQineQUvHJye+LJSL+AHj1uxOWyBNQYUT2mf7h3GiIyEXiM4CPM01T1oSPVz83N1eXLl7dLbMaYw5VWN7B+TzlrdxSRt2MPRcVFeKvLSaSWZFctMeI7UNeFEEsECQEP8d4IkhqiyNAU0typRLtjD2vb7/YRiAZXgoeIlFiiuiQQ3SURd1I0kgAa7yUgNfj9Vfh8lfh8zqe/Cn/I+v5EVd9QSGXlOmKie9Gv34/JyBj3le2WE5EVqpp7WHlLkoyIbKORzmJVPeEGZFqSMSb81Hn9bCqsZN2eCtZ/Ucz23QWU7S0hNlBNstSR7KolVr6cKsblcpEQE0O8K4IYL0TXQUw1xNd5iJY4Yt0JxHoSiGokEQU8ATRGcCdFEpEWR3RGAp6UGNxJkbiTonAnReEKefvl3r3/ZXPeb6iu3kxSUi4D+v+UxMRT2+XvEk6ON8mEvO6NaGAKkKqqP2u9EMODJRljOgd/QNmxt5r1+RWs31PB57v2sju/EK2rIFlqSZZa0jz1RGv9gX3cbjepKSkkxccTG+Eh0ucjoroBV1k9WtkA1QEi/JEHklCMJ4Fo9+Fvogx4FIl340mOIvmCvkT1TSA//2W2bP0TXu9eumZOpm/fu4mO7taef5IOdVxJ5ggNnn7ckYUZSzLGdG5FlXWs31NxIPls3FPKvtK9JEktyVJHuqeOVHc9kf4vHxhwuVykpaWRkZFBakoK8VGRRGoAqaumuqSU2sJ9eEtr8Vc04K4XYtzxxLgTSInqSownni63DSO6dxI+XyXbd/wfO3f+C3DRq9e3OanXrXg8neuVycfieK9kTgv56gJyge+q6tDWCzE8WJIx5sRTXe9jQ0HlgcSzfk85mwv2EeOvIUlqSfPU0T3KS6LU4mo48AAtInIg+exfUlNTiRalpqyUbUuXk742lfiYFLLuyiUiM5hMamt3s2Xr7yksfIvIyAz69rmbrKwrCA47PDEdb5L5T8hXH7ANeFRVT7jRh5ZkjPlq8PkDbCupDt7ncZLPuj3lVNTUkyR1JEkt2XE+MiMbiAtU46+rwhkJi4iQkpJCRkYGUbvzOaVgIFEJCXT7wQg8yV8+ZVZe/imbNz9EecWnxMefTP9+95OaelZHnXKbOt4k02f/1CwhZb2d98qcUCzJGPPVpaoUVDjdbU7yWbengi9Ka3ARIFHq6BntpXdCgHRPHa6qEmKjI+ldUsFQ39lEpsWRdWcu7riIg9osKppN3pZHqKvbTXr6BfTrex9xcSfWc1PHm2RWqupph5TZPRljzFdCRZ2XDfmVrNtTfiD5bCqsJDVQwYSoDYwccQaV73zAiNhxRHZPIPP24Qc9gQbg99ezc9czbN/+dwKBOrp3v54+ve8iIqKJWZ87mWNKMiIyEBgMPAJMDdmUCExV1cGtHWhHsyRjjGmJBl+AR+dvZN1HC+gfUcY1l17Mmr/PYGTaJUQPSCH95sGI+/C50RoaSti67c/s3v0SHk88vbPvPCEGczaVZJqbHS4HuARIBi4NWU4DvtPaQRpjTGcR6XFx53n9yPP0xqculq5ey6nfvJQVJfOo37SPstc209g/4iMj0xmY82vOHDGbpMRhbM77DUuWjqeoaF6j9Tu7IyYZVX1TVW8BLlHVW0KWu1Q17N8nY4wxbSkhOoJvnz+ITxq6s23bNrwJKWSOH8LassXUrCiiYt6OJveNjx/AsGFPM2zoNFyuKNasvYOVK6+jomJ1O55B22vpPNefisj3ROTvIjJt/9KmkRljTCdw48iTqIzrSY0ngblz5zL8ksvxDnSRV7mKyoU7qVx82Jy8B0lLG8OIM94mJ+fXVNdsYdnyy1m3/m7q6vLb6QzaVkuTzPNAV2AcsIjgbMaVbRWUMcZ0FtERbn54YQ7vV/egqqqKhQsXMv6OH7AzIY/dtXmUv72Vms+KjtiGy+WhR/fr+dqo9znppNspKprDx0vGsmXrn/D5qo+4b7hraZLpp6oPANWq+ixwMW308i9jjOlsrjitO0npmeRHdGPp0qXsLdvH5KkP8Fn9fyn1F1A6YxN1m8uabcfjSaBf36mMPHM+Gelj2b79r3y85AL27Hk5+KqETqilSWb/zHP7RGQIkAR0aZuQjDGmc/G4XUwdl8N/KjNxRUQxe/Zs4lJSufSe+/ig4FWqtZy9z6+nYVfLOoBiYnowZMifyT39ZaKje/D5hvv4ZNlkSks7363wliaZJ0UkBXgAmAWsJ/hYszHGGGDc4K6c3CONzwK92LlzJ5999hlZ/XI4/7bbWbDjeeoDtZQ8vQ5fSfMvWdsvKek0ck9/mcGDH8Pn3cenq77OZ6tvo7p6a/M7h4kWJRlV/aeqlqnqIlXto6pdVPUfbR2cMcZ0FiLCveMHsrwqkcikDN59911qamo4+exzGXrZRBZsfw5ffT3F09bir2z+BWmh7XbNvJSRI+fTt89UysqWsPSTCWzc9Cu83ua74Dpai5KMiGSKyL9E5B3n+yAR+VbbhmaMMZ3LWf3SObtfBu9Wdqeuro733nsvWH71jWQOG8D7X/wbX3kdJdPWEqjzNdPawdzuaLKzb2fUqPfoljWFXbue56OPz+eLL6a16K2eHaWl3WXPAPOA/S9H2AT8sC0CMsaYzmzquBy210QQkZXDihUr2LVrF+JyMeHOu3FlRvJxySy8hdXsfX496gscdftRkekMHPggZ454m8TEoWzOeyg4mLM4PAdztjTJpKvqTCAAoKo+oHM+6mCMMW1oaM9kJp7SlRm7EoiLj2f27NkEAgEio2OYfO/PKAnsYXXdB9RvKad0xkY0cGyJIT4+h+HDnnEGc0ayZs0drPz0eioq1rTyGR2fliaZauftmAogIiOB8jaLyhhjOrEfXZhDpReqM4aQn5/P/vkQEzO6MOnun7Kx4BO2R26gdk0J+97aclxXIAcN5qzOY9nyyaxbf0/YDOZsaZL5EcGnyvqKyIfAc8D3WzsYEfm9iGwQkdUi8rqIJDvl2SJSKyKrnOUfIfucLiJrRCRPRB4XEXHKU0Vkvohsdj5PjKlOjTFhr1+XeKac3pPpmwJ075XNe++9R2Vl8PHl7gMHceGtd7J045uUppRQ/XE+lQt3HtfxDhrM2es2Cgtn8/GSsWzd+liHD+Y8YpIRkV4AqroSGAN8DbgNGKyqbTHBznxgiKqeSvC+z/0h27ao6jBnuT2k/AmCk3X2d5bxTvl9wHuq2h94z/lujDHt4gdj+4MImyL74fP5mD9//oFtQ84dS+6lVzB/5b+oy/RSMW8H1csKjvuYHk8C/frdy6iR75KefgHbtv+Fj5eMZc+eVzpsMGdzVzJvhKzPUNV1qrpWVb1N7nEcVPVd534PwBKC09c0SUSygERVXaLB683ngMnO5knAs876syHlxhjT5rolx3DzqJN4dV05A4edwerVq9m+ffuB7aOvv5new3N565PH0W5uyl7bTO36va1y7JiYnpwy5HFOP30m0dHd+HzDj4ODOcs+bpX2j0ZzSUZC1tv7NW7fBN4J+d5bRD4VkUUiMtop6w7sCqmzyykDyFTV/Z2SBUBmm0ZrjDGHuOPcfsRFeliwN4Xk5GRmz56N3x+8onC53Fx8172kdOvG7M+ewNUlir3TN1C/vfVudycnnU7u6a98OZjz0xv5bPVt1NS030uNm0sy2sT6MRORBSKytpFlUkidnwI+4N9OUT7QS1WHE7w/NF1EElt6TOcqp8n4ReRWEVkuIsuLi4uP6byMMeZQKXGRfOecPszbUMKA3NEUFxezZMmSA9ujYmOZPPUB/Ph4f+d03EkRlDyzHm9h691HOXgw5z2UlX3MkqXj220wZ3NJZqiIVIhIJXCqs14hIpUiUnEsB1TVsao6pJHlTQAR+QbBF6Xd4CQHVLVeVfc66yuALcAAYDcHd6n1cMoACp3utP3dak1Og6qqT6pqrqrmZmRkHMtpGWNMo751dm/S4iJ5bn0DOTk5LFy4kPLyL69WkrtmcdmP7qe4YBvLG95DIoSSaWvx7atv1TiCgzm/y6hR75OVdZUzmPMCvtj5dJsO5mzupWVuVU1U1QRV9Tjr+7+3+EqipURkPHAvcJmq1oSUZ4iI21nvQ/AG/1anO6xCREY6T5XdBLzp7DYLuNlZvzmk3Bhj2k1clIfvn9+PJVtLSR04AlVl7ty5B9XpOfhULvjmd9m0+kO2Z2wmUOenZNoaAjWtf/s7KjKdkwc+FBzMmXAKmzc/yJKl4ykufrdNBnO29BHm9vJXIAGYf8ijyucAq0VkFfAKcLuqljrb7gD+CeQRvMLZfx/nd8CFIrIZGOt8N8aYdnfdmb3okRLDXxbv4ZxzzuHzzz9n8+bNB9U5dex4ho+/lI/fm0HFqTX4SusoeWYdgYa2eSosPj6HYcOeYejQfyESweo136WoaHarH0fCcRqCjpSbm6v7B04ZY0xreXXFLu5++TMev/ZUdnzwBoFAgDvuuIOIiIgDdQJ+P6/97hfsXLeGKTf9DBZVE52TStrXT0bcbXdNEAj4KCh8g66Zk3C5IprfoREiskJVcw8tD7crGWOMOSFNHt6dAZnx/GnBFsZNmEBZWRmLFy8+qI7L7eaSH/yYpC6ZzHrlD0Sd34W6DaWUvZbXpvOSuVweumVddcwJ5ohtt3qLxhhjDuN2CVPHDWRbSTUrSiMZMmQIixcvZu/eg8fGRMfHM/nenxEI+Jnz7l+IG5NFzYpCKubt6KDIj48lGWOMaSdjT+7Cab2SeWzBJs49fyxut5t33nnnsKuU1G7dueSH97F31xcsWvMisSMyqVy4k8rFu5toOXxZkjHGmHYiIvx4/EAKK+p5dc1ezj//fPLy8vj8888Pq5t96nDOvek7bFmxlHW1HxEzOI3yt7dS81mTozHCkiUZY4xpR2f2SWPMgAz+vnALOacMJzMzk7lz51Jff/i4mOHjL+HUseP5ZNYrFPYsJLJ3IqUzN1G3OfzfiLmfJRljjGlnU8flUF7r5V+Lt3PxxRdTUVHBokWLDqsnIpx/y+30HHQK7/7zcbxfiyAiI4a9z39Ow67KDoj86FmSMcaYdjakexKXDu3GvxZvIzqlC8OHD2fJkiUUFR3eFeb2eLj0R/cTn5rGrL/8hqjJWbhiPZQ8sw5fSW0HRH90LMkYY0wHuPvCAXj9Af76fh5jx44lKiqK2bNnN/qockxCIpOnPoCvoZ63nniY5Bv7Q0ApnrYWf2XbTQnTGizJGGNMB8hOj+PqM3oyfekX7K0Txo4dy44dO1i9uvFXdaX3PImLf3AvRTu2Mn/mE6TdPIhAZQMl09YSqPM1uk84sCRjjDEd5AcX9MftEv44fyPDhw+ne/fuvPvuu9TWNt4N1mf4GYy54RY2L/2IFZ+8TdqNJ+MtrGHv8+tRX6Cdo28ZSzLGGNNBMhOjueWs3rz52R42FlZxySWXUFNTw/vvv9/kPqdfcjmDx4zl41deZEfpOlKu6k/9lnJKZ25EA+E3TZglGWOM6UDfHdOXhCgPf5i3kaysLM444wyWL1/Onj17Gq0vIoz9zvfoljOIuX9/jKrkSpIm9qZ2dQn73trSptPPHAtLMsYY04GSYiO4/dy+vLehiGXbSzn//POJjY1l9uzZBAKNd4F5IiKYdPdPiElM5I1HfoUMiSF+dHeqP86ncuHOdj6DI7MkY4wxHeyWr/UmIyGKR+ZuICoqinHjxrF7925WrlzZ5D6xSclMnvoA9TU1vPmHB4m9oBuxw7tQMW8H1csK2jH6I7MkY4wxHSwm0s1dF/Rn2fYyFm4s5pRTTiE7O5sFCxZQXd30q5i7ZPdhwvfvpmDLZuY/+ReSr+xH1IAUyl7bTO36vU3u154syRhjTBi49oyenJQWy8NzN6AKEydOpKGhgfnz5x9xv/5njOLsa29iw4eLWPbWq6TdcDIR3ePZO30D9dvLj7hve7AkY4wxYSDC7eJHFw5gQ0Elb63eQ5cuXRg1ahSrVq3iiy++OOK+IyZPYeBZY1j80nNs+Wwp6d8YjCc5ipJn1uMtbPpKqD1YkjHGmDBx6andODkrkUff3USDL8CYMWNITEzk7bffxu9v+jXMIsJFt99F134DeOevf2RvyS7SvzkEiXBRMm0tvn2HT77ZXizJGGNMmHC5hHvH5fBFaQ0zln1BZGQkEyZMoKioiE8++eSI+0ZERjHpnv8lKi6ON37/axrcdaR/cwiBOj8l09YQqPG201kcLOySjIj8QkR2i8gqZ5kYsu1+EckTkY0iMi6kfLxTlici94WU9xaRpU75DBGJbO/zMcaYo3FuTgYjslN5/P08ahp8DBw4kP79+/Of//yHioqKI+4bn5LK5KkPUFtRwZuP/gZXeiTpNw/CV1pHyTPrCDQ0fTXUVsIuyTj+pKrDnGUOgIgMAq4FBgPjgb+LiFtE3MDfgAnAIOA6py7Aw05b/YAy4FvtfSLGGHM0RIR7x+dQXFnP0x9uR0SYMGECfr+fefPmNbt/Zp9+jL/jf9izcT0Lnvobkb2TSLt2IA07KymdvgH1t+/0M+GaZBozCXhJVetVdRuQB4xwljxV3aqqDcBLwCQREeB84BVn/2eByR0QtzHGHJXc7FTGntyFfyzawr6aBlJTUxk9ejTr1q1jy5Ytze6fM+psRl11HesWLWDF268TMySd5En9qNtQStlree06K0C4Jpk7RWS1iEwTkRSnrDsQOpR1l1PWVHkasE9VfYeUH0ZEbhWR5SKyvLi4uDXPwxhjjsk943KoqvfxxKJgUjnrrLNITU1lzpw5+HzNz7o86srrGHDmWSz699Ns/XQZ8SOzSLigFzUrCqmYt6Otwz+gQ5KMiCwQkbWNLJOAJ4C+wDAgH3i0reNR1SdVNVdVczMyMtr6cMYY06yBXROZPKw7z3y4nYLyOiIiIpg4cSJ79+7lo48+anZ/cbkYf8f/0OWkPsz+8yOU7NxB4thexJ3ZlcqFO6n8cHc7nEUHJRlVHauqQxpZ3lTVQlX1q2oAeIpgdxjAbqBnSDM9nLKmyvcCySLiOaTcGGM6hf8ZO4CAKo+/vxmAfv36MWjQIP773/9SVlbW7P4R0dFMvvcBIqKieeP3v6a2soLkSf2IGZxG+dtbqfns8Ddxtraw6y4TkayQr5cDa531WcC1IhIlIr2B/sAnwDKgv/MkWSTBhwNmabDT8T/AVc7+NwNvtsc5GGNMa+iVFsv1I3oxY9lOtpUEB1WOGzcOEeGdd95pURsJaelMuud/qSrdy1t/+i2BgI/UawcSmZ1I6cxN1G1uPlkdj7BLMsAjIrJGRFYD5wH/A6Cq64CZwHpgLvA954rHB9wJzAM+B2Y6dQF+DPxIRPII3qP5V/ueijHGHJ87z+9PpNvFo+9uBCApKYlzzz2XTZs2sWHDhha1kdU/h4tuu4td69fy/rT/A4+QftNgIjJi2Pv85zTsqmyz+MMuyajq11X1FFU9VVUvU9X8kG0PqWpfVc1R1XdCyueo6gBn20Mh5VtVdYSq9lPVKaraccNejTHmGGQkRPGts3vz9up81u4OzkU2cuRIMjIyeOedd2hoaGhRO4NGn8eISVex+r25fDr3bVwxHtK/OQRXrIeSZ9bhK2n8bZzHK+ySjDHGmIPdOqYPybER/H5e8GrG7XZz8cUXU15ezgcffNDids6+9ib65o5k4bNPsf2zlbgTo0j/1hAIKMXT1uKvbFnCOhqWZIwxJswlRkdwx7l9WbSpmI+3BKfwz87OZujQoXz44YeUlJS0qB1xuZh4549I69mLtx97mNI9u4jIiCX9liFovQ9vYU2rx25JxhhjOoGbRmXTNTGaR+ZtODCY8sILLyQiIoLZs2e3eIBlZEwsk6c+gMvt5o1Hfk1dVRWRPRPoeu8Iovslt3rclmSMMaYTiI5w84Ox/fn0i33MX18IQHx8PBdccAHbtm1j3bp1zbTwpaQumVx2z08pLyrkrcd+R8DvxxXlbpO4LckYY0wnMeX0HvRJj+P38zbiDwSvXHJzc8nKymLu3LnU1dW1uK0eAwcz9jt38MWaVSx87p9tFbIlGWOM6Sw8bhd3X5TD5qIq3vg0OLbc5XJxySWXUFVVxcKFC4+qvVPOu4jTL57Mp3Pf4rP5LRt3c7QsyRhjTCcyYUhXTumexB/nb6LeF5y6v3v37uTm5rJ06VIKCgqOqr1zbryF7GGn8/7T/2Dn+jWtHq8lGWOM6URcLmHquBx276tl+tIvX8t8wQUXEBMTw+zZswkEWj6dv8vl5pIf3MuAkWeT3DWr+R2ONt5Wb9EYY0ybGt0/nVF90vjr+3lU1QdnZI6JieHCCy9k586drFq16qjai4qN4+K7ppKQmt7qsVqSMcaYTmb/i832Vjfwrw+2HSgfOnQovXr1Yv78+dTUtP6Yl2NhScYYYzqh4b1SGDc4k6c+2EppdXCkvsvl4uKLL6auro733nuvgyMMsiRjjDGd1D0X5VDT4OPv/8k7UJaZmcnIkSNZsWIFu3bt6sDogizJGGNMJ9U/M4ErTuvBc0t2sHvflxNcnnvuuSQkJPD2228f1UMAbcGSjDHGdGI/HNsfFP68YNOBsqioKMaNG0dBQQHLli3rwOgsyRhjTKfWIyWWG0eexCsrdpFXVHWgfPDgwfTp04f333+fysq2e19McyzJGGNMJ/e98/oSE+E+8GIzCD6BNnHiRHw+H/Pnz++w2CzJGGNMJ5cWH8W3R/fhnbUFfLZz34Hy9PR0zjrrLFavXs327ds7JDZLMsYYcwL49ujepMZF8si8g1/JPHr0aJKTk5k9ezY+n6/d47IkY4wxJ4CE6Ai+d14/Pszby+LNX77ELCIiggkTJlBcXMySJUvaPa6wSjIiMkNEVjnLdhFZ5ZRni0htyLZ/hOxzuoisEZE8EXlcRMQpTxWR+SKy2flM6ajzMsaY9nDDmb3onhxz0IvNAHJycsjJyWHRokWUl5e3a0xhlWRU9RpVHaaqw4BXgddCNm/Zv01Vbw8pfwL4DtDfWcY75fcB76lqf+A957sxxpywoiPc/HBsf1bvKmfu2oNnY54wYQKqyty5c9s1prBKMvs5VyNXAy82Uy8LSFTVJRpM288Bk53Nk4BnnfVnQ8qNMeaEdcVpPejXJZ7fv7sRn//LgZjJycmMGTOGzz//nM2bN7dbPGGZZIDRQKGqhv4leovIpyKySERGO2XdgdB5E3Y5ZQCZqprvrBcAmU0dTERuFZHlIrK8uLi4lU7BGGPan9sl3HNRDluLq3l15cHTyowaNYr09HTmzJmD1+ttl3jaPcmIyAIRWdvIMimk2nUcfBWTD/RS1eHAj4DpIpLY0mM6Vzl6hO1PqmququZmZGQc5RkZY0x4GTc4k6E9k3lswWbqvP4D5R6Ph4kTJ1JWVsbixYvbJZZ2TzKqOlZVhzSyvAkgIh7gCmBGyD71qrrXWV8BbAEGALuBHiHN93DKAAqd7rT93WpFbX1uxhgTDkSEH4/PIb+8jheW7DhoW58+fRgyZAiLFy9m7969bR5LOHaXjQU2qOqB6zwRyRARt7Peh+AN/q1Od1iFiIx07uPcBLzp7DYLuNlZvzmk3BhjTnhf65vO6P7p/O0/eVTUHdw1Nm7cONxuN3PmzDnoKbS2EI5J5loOv+F/zv+3d/9BXtT3HcefL7hwsUCJVWxMoEFRUBOL/NBGnUaCpyaNRU0wxTqOJjYpaatjqK11nEmdTjs1SVOrbYxBzOhkosSQNmKJaJ0WMGYQIYj8EgMCEx0CBlESQUV594/9HO59/d6P7/e+e98f93rM7NzuZz+7+3nf3t77Pvvd2w/wTHqkeSEwJyJeTuv+ApgPbCHr4Tycym8BzpP0c7LEdUvRDTczayR/c8FE9u4/yPzlz3cpHzlyJDNmzGDr1q1s2rSp0Da0Fbr3KkTEVWXKfkj2SHO5+quAj5Qp3wOcW+v2mZk1i98f8z4+deqxzP/JNq44cxyjR7YfXnf66aezZs0alixZwvjx42lvb+9hT9VrxJ6MmZnVyNzzJ/DGW4f4Zm5gM4ChQ4dy4YUXsm/fPpYtW1bY8Z1kzMxa2PjRI/jstDF878kd/OLl/V3WjR07lsmTJ7NixQp27y7m2SgnGTOzFnftuSciiVtzA5t16ujooL29ncWLFxfyEICTjJlZizt21BFcddY4/mvNi2z+ZdcBzIYPH05HRwc7duxg48aNNT+2k4yZ2SDwpXPGM2JYG19/ZPO71k2ePJmZM2cyceLEmh/XScbMbBA4cvgw/vyc43ls0y5W79jbZd2QIUOYMmUKbW21f+DYScbMbJD43NnHcfSIYXx1ybOF/xNmJycZM7NBYnh7G9fMOJGV215m2XMD8zJgJxkzs0HksjN+jzFHHsHXlmzm0KHiezNOMmZmg8iwtiH89fkT2LhzH4vX7ex9g35ykjEzG2RmTvogJ71/JN94dDMHcwObFcFJxsxskOkc2Gz7nv08sOoXhR7LScbMbBA69+RjmPqhI7ntsZ9z4M23e9+gSk4yZmaDUDaw2Uns/vUb3PPT7YUdx0nGzGyQOuO43+HjE0fzraVbeHX/wd43qIKTjJnZIHb9BRPZ9/pbfHv51kL27yRjZjaIffgDo5g56QN854lt7N73es337yRjZjbIzT1vAiPf+x6e2/Wbmu+74YZfNjOzgTXu6OE8ccMMhrXVGmORogAACY1JREFUvt9Rl56MpEslbZB0SNK0knU3StoiabOkC3Lln0hlWyT9Xa78OElPpvLvSxqWytvT8pa0ftxAxWdm1myKSDBQv9tl64FPA8vzhZJOAWYDHwY+AdwhaaikocA3gU8CpwCXpboAXwVujYgTgL3A1an8amBvKr811TMzswFUlyQTEZsi4t0j58BFwIKIeCMitgFbgDPStCUino+IN4EFwEWSBMwAFqbt7wUuzu3r3jS/EDg31TczswHSaB/8fxDIv+PghVTWXflRwCsR8VZJeZd9pfWvpvrvIumLklZJWvXSSwPz+mszs8GgsA/+JT0GvL/Mqpsi4sGijluNiJgHzAOYNm3awIzkY2Y2CBSWZCKio4rNXgTG5pbHpDK6Kd8DvE9SW+qt5Ot37usFSW3AqFTfzMwGSKPdLlsEzE5Phh0HnAisBJ4CTkxPkg0jezhgUWTjh/4fMCttfyXwYG5fV6b5WcD/xkCNN2pmZkD9HmG+RNILwJnAYkmPAETEBuABYCOwBPjLiHg79VL+CngE2AQ8kOoC3ADMlbSF7DOXu1P53cBRqXwucPixZzMzGxjyH/ddSXoJ2JErGkX20EBf5o8GflXlofP7q6ZOuXWlZc0QS6VxlC53zufLmiWWIs9JT+3sS51GiqURrpVm/PkqXa51LB+KiNHvKo0ITz1MwLy+zgOranGcauqUW1da1gyxVBpHD+3PlzVFLEWek1aKpRGulWb8+So6lu6mRvtMphE9VOF8LY5TTZ1y60rLmiGWSuMoXX6omzrVGshYijwnfd1PM8TSCNdKM56T0uVax1KWb5fVkKRVETGt95qNz7E0nlaJAxxLoyoiFvdkamtevRtQQ46l8bRKHOBYGlXNY3FPxszMCuOejJmZFcZJxszMCuMkY2ZmhXGSGSCSLpZ0VxpI7fx6t6c/JB0v6W5JC3uv3VgkDZd0bzoXl9e7Pf3RzOehVKtcH5JOlnSnpIWSvlTv9vRXul5WSbqw2n04yfSBpO9I2i1pfUl52dE6y4mIH0XEF4A5wJ8U2d6e1CiW5yPi6p7qDKQKY/o0sDCdi5kD3theVBJLo52HUhXG0hDXRzkVxrEpIuYAnwXOrkd7e1LF9X8D2au+qlfr/+5sxQn4GDAFWJ8rGwpsBY4HhgFryUbtPBX475LpmNx23wCmtEgsC+t9bqqI6UbgtFTnvnq3vT+xNNp5qFEsdb0+ahEH2R8vDwN/Wu+29ycW4DyylxFfBVxY7TELe9V/K4mI5ZLGlRQfHq0TQNIC4KKI+GfgXV3LNCrnLcDDEfGzYlvcvVrE0mgqiYlsYLsxwNM0YE++wlg2DmzrKlNJLJI20QDXRzmVnpOIWAQskrQYuG8g29qbCmMZAQwnSzgHJP04Ig5VesyGu8iaSHejdXbnGqADmCVpTpENq0JFsUg6StKdwGRJNxbduCp1F9N/Ap+R9C0Kfp1GDZWNpUnOQ6nuzksjXx/ldHdOpku6XdK3gR/Xp2kVKxtLRNwUEdeRJcq7qkkwUOCgZdZVRNwO3F7vdtRCROwhu3fedCLiNeBz9W5HLTTzeSjVKtdHRCwFlta5GTUVEff0Z3v3ZKrX0yiezaaVYunUSjE5lsbTKnFAwbE4yVSv7GiddW5TtVoplk6tFJNjaTytEgcUHUu9n3Zohgm4H9gJHCS7X3l1Kv8j4DmyJzNuqnc7B1ssrRiTY2m8qVXiqFcsfkGmmZkVxrfLzMysME4yZmZWGCcZMzMrjJOMmZkVxknGzMwK4yRjZmaFcZKxppPe2fV0mn4p6cXc8rAK9jNf0ik1atPb6fjrJf1A0m/VYr/9bNN0SWf1cx/PS5pYUvZvkm7oYZvtko7uz3GtdTjJWNOJiD0RcVpEnAbcCdzauRwRb1awnz+LiFq9yfhAOv5HgDfp4zvFJBX5/sDpQEVJpkx7FpD9B3jn+iHArFRu1isnGWsJku6RNCu3/Jv0dbqkpcpGKnxW0vfSsAuk8mmd9SX9k6S1klZI+t1UPj4tr5P0j5377cXjwAmS/ljSk5LWSHost8+bJX1X0hPAdyWNk/S4pJ+l6axc25dJejD1KG6RdLmklak941O90ZJ+KOmpNJ2dXuc+B/hy6mH9Ybl65dpTEsv9dB1E7GPAjojYIelHklZL2iDpi2XOyTjlBseSdL2km3Pf1yVp+8clnZTKL029wbWSlvfhe20NzknGBoPJwHVk42IcT/kRC4cDKyJiErAc+EIqvw24LSJOJXsNR49ST+CTwDrgJ8BHI2Iy2V/+f5uregrQERGXAbuB8yJiCtkv9PzbiCeRJYuTgSuACRFxBjCf7PX4nW28NSJOBz4DzI+I7XTt5T1erl437TksItYBhyRNSkWzyRIPwOcjYiowDbhW0lG9fX9y5gHXpO2vB+5I5V8BLkjnoeFGLrXK+VX/NhisjIgXACQ9DYwjSwB5b5KN/AmwmmxUQIAzgYvT/H3Av3RzjCPSviHrydwNTAS+L+lYshEHt+XqL4qIA2n+PcB/SDoNeBuYkKv3VETsTG3fCjyaytcBH0/zHcApqYMG8NuSRpRpY0/18u0pdT8wW9IGsu/F36fyayVdkubHAicCe7rZx2HpmGcBP8i1pT19fQK4R9IDZGP/WJNzkrFW8RapZ54+N8g/APBGbv5tyv/cH4x3XuTXXZ2eHEifER0m6d+Bf42IRZKmAzfnVr+Wm/8ysIus1zIEeL2bth/KLR/KtXEIWY8pvx25X+D0od5rpZVzFpAlt2XAMxGxK8XTAZwZEfslLQXeW7Ld4XOSdK4fArxS+v0CiIg5kv4A+BSwWtLUyMbNsSbl22XWKrYDU9P8TLLeQS2sILu1BLkPwPtoFO+My3FlL/V2Rjby4BVkY65X4lHeuXVG6hEB/BoY2Yd6PYqIrcCvyIZH7rxVNgrYmxLMScBHy2y6CzhG2dOA7aShvCNiH7BN0qWpHeq8HSdpfEQ8GRFfAV6i6zgn1oScZKxV3AWcI2kt2S2unv4yr8R1wFxJzwAnAK9WsO3NZLeEVpP9ku7OHcCVqe0nUXnbrwWmSXpG0kbeebLtIeCSzg/+e6jXF/entnXewloCtEnaRJZ8VpRuEBEHgX8AVgL/AzybW305cHWKeQPZmPIAX08PNawHfgqsraCN1oD8qn+zHij7f5cDERGSZgOXRcRFvW1nZhl/JmPWs6lkH8oLeAX4fJ3bY9ZU3JMxM7PC+DMZMzMrjJOMmZkVxknGzMwK4yRjZmaFcZIxM7PCOMmYmVlh/h/RBN1oEjujBQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA5ca8qrtyhz"
      },
      "source": [
        "# Task: Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sAAjno02IjF"
      },
      "source": [
        "## Step 1: \n",
        "\n",
        "First we divide the data into K equal parts. Below I'm going to use the resulting dataframe with 80 rows and 5 columns.  Each column is a 'split' aka a fold. We will use the folds for the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVgd6L0De51l"
      },
      "source": [
        "### Algorithms\n",
        "**Functions**\n",
        "* Cross Validation Split: computes folds\n",
        "* CV: computes Cross Validation\n",
        "\n",
        "**Summary of Initialized Variables**\n",
        "\n",
        "* X_d2 is the normalized training data centered and scaled to have unit standard deviation\n",
        "* Y_d2 is the true values data (i.e. Credit Balances) generated as ùëÅ-dimensional centered response vector ùê≤\n",
        "* K is the number of folds\n",
        "\n",
        "Same parameters as before repeated again as:\n",
        "\n",
        "* b_d2 will be our random initialized parameter vector of length = dim k.\n",
        "* tune is the Tuning Parameters Vector aka our lambda used in our Cost Function Equation\n",
        "* maximum iteration is 1000\n",
        "* alpha is initialized to 10^(-5) as suggested to act as proof of convergence within 1000 iterations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8mzwVWckkzg"
      },
      "source": [
        "### Cross Validation Split Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j5qxSfgmmNg"
      },
      "source": [
        "# Set K parameter for K-fold Cross Validation\n",
        "K = 5\n",
        "\n",
        "# Import Library for randomization\n",
        "import random\n",
        "from random import randrange\n",
        "\n",
        "# Cross Validation Split Function\n",
        "def cross_validation_split(dataset, folds= K):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / folds)\n",
        "\tfor i in range(folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmusRA1UkaOs"
      },
      "source": [
        "### Initialize Variables for Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGSdDYUXeWdL",
        "outputId": "4518e0f1-87d6-414d-d1b3-598b821508c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        }
      },
      "source": [
        "# Grabbing 5 data folds from X data\n",
        "random.seed(1)                                # random seed\n",
        "                                              # d2 = (training_data.iloc[:,: -1]).values \n",
        "                                              # .values turnes into np array\n",
        "d2 = X.values\n",
        "X_folds = cross_validation_split(d2, K)       # cross validation\n",
        "X_folds_df = (pd.DataFrame(X_folds))          # convert to dataframe\n",
        "X_folds_df.T                                  # Transposed dataframe\n",
        "                                              # Note: fold_size = total_rows / total_folds\n",
        "groups = pd.Series(['k1', 'k2', 'k3', 'k4', 'k5'])\n",
        "X_d2 = (X_folds_df.T).rename(columns = groups, inplace = False)\n",
        "X_d2 "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k1</th>\n",
              "      <th>k2</th>\n",
              "      <th>k3</th>\n",
              "      <th>k4</th>\n",
              "      <th>k5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.4928995107556017, 0.3827226588126472, 0.40...</td>\n",
              "      <td>[-0.8363879391677917, 0.02270168363344191, 0.0...</td>\n",
              "      <td>[-0.11899479329187766, -0.21947849100575875, -...</td>\n",
              "      <td>[-0.8088657373207883, 0.23325546695124427, 0.2...</td>\n",
              "      <td>[-0.929594571196046, 0.28567729366205513, 0.23...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.17912456217870565, 0.15613906071550596, 0.1...</td>\n",
              "      <td>[-0.3490747260520339, -1.2778795046794031, -1....</td>\n",
              "      <td>[1.8655262003008712, 0.8345901402950914, 0.730...</td>\n",
              "      <td>[0.022361505266649616, 0.8237591843631057, 0.8...</td>\n",
              "      <td>[-0.4141633147499988, -0.6249894810993041, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.7916998279213686, -1.4732699496924255, -1....</td>\n",
              "      <td>[0.23215445419112807, 0.2527511876288186, 0.14...</td>\n",
              "      <td>[2.349916952808133, 0.9732263762245086, 1.0538...</td>\n",
              "      <td>[-0.7789601695406422, 0.14574134302079966, 0.0...</td>\n",
              "      <td>[-0.5460428963838877, -1.0517291448195414, -1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2.524158026563235, 1.3440783073356997, 1.3447...</td>\n",
              "      <td>[-0.704054383070447, -0.08344168450001814, -0....</td>\n",
              "      <td>[-0.6300849189311295, -1.4407770818964685, -1....</td>\n",
              "      <td>[-0.6204947083906271, -0.9434195854996842, -0....</td>\n",
              "      <td>[-0.1229670698471153, 0.12018028702131338, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.622395726456348, 0.3064727290514677, 0.336...</td>\n",
              "      <td>[0.38480336752811667, 1.1551864358818686, 1.18...</td>\n",
              "      <td>[3.3511860053637075, 1.7313932914635088, 1.816...</td>\n",
              "      <td>[-0.6894988268358977, -1.5174602498949272, -1....</td>\n",
              "      <td>[-0.8204137127349433, 0.3164372085088946, 0.37...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>[0.7866842613022995, 1.6755055588544625, 1.719...</td>\n",
              "      <td>[-0.5158252211601159, -1.1154151656996174, -1....</td>\n",
              "      <td>[-0.49440330116579867, -0.4023050271376777, -0...</td>\n",
              "      <td>[-0.4899203033391734, -0.5106145864575349, -0....</td>\n",
              "      <td>[-0.6860940183599799, -1.4243140288798501, -1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>[-0.9825960898045022, -0.2974613737160559, -0....</td>\n",
              "      <td>[0.48785557073256686, 0.7457763016528085, 0.64...</td>\n",
              "      <td>[-0.7112896010817727, -0.9052946206190945, -1....</td>\n",
              "      <td>[-0.016254697531053162, -0.13196436707531414, ...</td>\n",
              "      <td>[-0.7286824977129204, -1.461572517285881, -1.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>[-0.8334087317513637, 0.014036918887853333, 0....</td>\n",
              "      <td>[-0.826116766932106, 0.28351110247565803, 0.40...</td>\n",
              "      <td>[0.22951572762229155, -0.8125816378412967, -0....</td>\n",
              "      <td>[0.6176922672809046, 0.38055646762625006, 0.48...</td>\n",
              "      <td>[-0.5931427469674195, -0.5747338455748904, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>[0.41595736508276576, 0.940300270191272, 1.112...</td>\n",
              "      <td>[-0.6321561774206461, 0.08118884566616479, 0.0...</td>\n",
              "      <td>[-0.9015616480776546, -1.667793918230889, -1.5...</td>\n",
              "      <td>[0.09303965454591347, 0.5651159567072866, 0.65...</td>\n",
              "      <td>[-0.23521225593654393, 0.6591286541969228, 0.5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>[-0.9018737555212806, -1.5603508353855908, -1....</td>\n",
              "      <td>[-0.17332986188673508, -0.6700462577763646, -0...</td>\n",
              "      <td>[0.22693374786138706, 0.08985361041175337, 0.0...</td>\n",
              "      <td>[0.4060550470986378, 1.2054420714062823, 1.215...</td>\n",
              "      <td>[-0.8656125452527543, -1.1648043247494724, -1....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows √ó 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   k1  ...                                                 k5\n",
              "0   [-0.4928995107556017, 0.3827226588126472, 0.40...  ...  [-0.929594571196046, 0.28567729366205513, 0.23...\n",
              "1   [0.17912456217870565, 0.15613906071550596, 0.1...  ...  [-0.4141633147499988, -0.6249894810993041, -0....\n",
              "2   [-0.7916998279213686, -1.4732699496924255, -1....  ...  [-0.5460428963838877, -1.0517291448195414, -1....\n",
              "3   [2.524158026563235, 1.3440783073356997, 1.3447...  ...  [-0.1229670698471153, 0.12018028702131338, 0.1...\n",
              "4   [-0.622395726456348, 0.3064727290514677, 0.336...  ...  [-0.8204137127349433, 0.3164372085088946, 0.37...\n",
              "..                                                ...  ...                                                ...\n",
              "75  [0.7866842613022995, 1.6755055588544625, 1.719...  ...  [-0.6860940183599799, -1.4243140288798501, -1....\n",
              "76  [-0.9825960898045022, -0.2974613737160559, -0....  ...  [-0.7286824977129204, -1.461572517285881, -1.3...\n",
              "77  [-0.8334087317513637, 0.014036918887853333, 0....  ...  [-0.5931427469674195, -0.5747338455748904, -0....\n",
              "78  [0.41595736508276576, 0.940300270191272, 1.112...  ...  [-0.23521225593654393, 0.6591286541969228, 0.5...\n",
              "79  [-0.9018737555212806, -1.5603508353855908, -1....  ...  [-0.8656125452527543, -1.1648043247494724, -1....\n",
              "\n",
              "[80 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORcRtgZOefzK",
        "outputId": "d5d84ae1-2999-4ced-ae64-bb649b786d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Grab the 5 datafolds for true value Y data\n",
        "random.seed(1)                                   # random seed\n",
        "# balance = (clean['Balance']).values          # np array\n",
        "balance = Y.values\n",
        "Y_folds = cross_validation_split(balance, K)   # cross validation\n",
        "Y_folds_df = (pd.DataFrame(Y_folds))      # convert to dataframe\n",
        "Y_folds_df.T                              # Transposed dataframe dim: 80 x 5 \n",
        "# Note: there are 80 rows per fold as we expected: fold_size = total_rows / K\n",
        "Y_d2 = (Y_folds_df.T).rename(columns = groups, inplace = False)\n",
        "Y_d2"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k1</th>\n",
              "      <th>k2</th>\n",
              "      <th>k3</th>\n",
              "      <th>k4</th>\n",
              "      <th>k5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[301.985]</td>\n",
              "      <td>[168.985]</td>\n",
              "      <td>[-274.015]</td>\n",
              "      <td>[342.985]</td>\n",
              "      <td>[434.985]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-39.014999999999986]</td>\n",
              "      <td>[-520.015]</td>\n",
              "      <td>[-129.015]</td>\n",
              "      <td>[525.985]</td>\n",
              "      <td>[11.985000000000014]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-520.015]</td>\n",
              "      <td>[20.985000000000014]</td>\n",
              "      <td>[-270.015]</td>\n",
              "      <td>[211.985]</td>\n",
              "      <td>[-520.015]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[5.985000000000014]</td>\n",
              "      <td>[533.985]</td>\n",
              "      <td>[-520.015]</td>\n",
              "      <td>[-101.01499999999999]</td>\n",
              "      <td>[28.985000000000014]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[391.985]</td>\n",
              "      <td>[582.985]</td>\n",
              "      <td>[8.985000000000014]</td>\n",
              "      <td>[-504.015]</td>\n",
              "      <td>[436.985]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>[834.985]</td>\n",
              "      <td>[-520.015]</td>\n",
              "      <td>[-200.015]</td>\n",
              "      <td>[-357.015]</td>\n",
              "      <td>[-520.015]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>[-55.014999999999986]</td>\n",
              "      <td>[241.985]</td>\n",
              "      <td>[-520.015]</td>\n",
              "      <td>[276.985]</td>\n",
              "      <td>[-520.015]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>[224.985]</td>\n",
              "      <td>[424.985]</td>\n",
              "      <td>[-520.015]</td>\n",
              "      <td>[-38.014999999999986]</td>\n",
              "      <td>[-326.015]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>[511.985]</td>\n",
              "      <td>[142.985]</td>\n",
              "      <td>[-520.015]</td>\n",
              "      <td>[291.985]</td>\n",
              "      <td>[455.985]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>[-520.015]</td>\n",
              "      <td>[-520.015]</td>\n",
              "      <td>[-138.015]</td>\n",
              "      <td>[655.985]</td>\n",
              "      <td>[-520.015]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows √ó 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       k1  ...                    k5\n",
              "0               [301.985]  ...             [434.985]\n",
              "1   [-39.014999999999986]  ...  [11.985000000000014]\n",
              "2              [-520.015]  ...            [-520.015]\n",
              "3     [5.985000000000014]  ...  [28.985000000000014]\n",
              "4               [391.985]  ...             [436.985]\n",
              "..                    ...  ...                   ...\n",
              "75              [834.985]  ...            [-520.015]\n",
              "76  [-55.014999999999986]  ...            [-520.015]\n",
              "77              [224.985]  ...            [-326.015]\n",
              "78              [511.985]  ...             [455.985]\n",
              "79             [-520.015]  ...            [-520.015]\n",
              "\n",
              "[80 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9YSKipd2E3e"
      },
      "source": [
        "## Step 2:\n",
        "\n",
        "Now that we've split the the data into k = 5 groups (columns in Step 1). \n",
        "\n",
        "So that we now run a 5-fold cross validation for every lambda in our tuning parameter vector and evaluated 5 times using the performance summarized by taking the mean performance score (using our gradient descent).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EQkLl_mfwzG"
      },
      "source": [
        "### Cross Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYQP9s15qrD9"
      },
      "source": [
        "# Cross Validation Algorithm\n",
        "def CV(X_d2, Y_d2, tune, alpha):\n",
        "  ''' \n",
        "  Cross Validation Function \n",
        "  :param X_d2: k-fold data dataframe\n",
        "  :param Y_d2: true values fold data dataframe\n",
        "  :param tune: tuning parameter of lambda values\n",
        "  :param alpha: learning rate\n",
        "  :return: beta updated dataframe for each fold, cost dataframe for each fold\n",
        "  '''\n",
        "  CV_5 = (gd(X_d2, Y_d2, tune, alpha, 1000))\n",
        "  cv_beta = CV_5[0] # beta_update\n",
        "  CV_5_beta = (cv_beta).rename(columns = groups, inplace = False)\n",
        "  CV_5_cost = CV_5[1]\n",
        "  CV_5_cost = (CV_5_cost.T).rename(columns = groups, inplace = False)\n",
        "  return CV_5_beta, CV_5_cost\n",
        "\n",
        "# Output for Viewing\n",
        "# print('Cross Validation beta updates for each k-fold:')\n",
        "# print(CV(X_d2, Y_d2, tune, alpha)[0])\n",
        "# print('')\n",
        "# print('Cost for each CV fold')\n",
        "# print(CV(X_d2, Y_d2, tune, alpha)[1])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Iii4UxzixY"
      },
      "source": [
        "### **Cross Validation beta updates for each k-fold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzsV69_dottN",
        "outputId": "fd6e34b8-1ba9-44c7-89a2-fd32b7959c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "CV_5 = (gd(X_d2, Y_d2, tune, alpha, 1000)[0]) # beta_update\n",
        "CV_5_beta = (CV_5.T).rename(columns = groups, inplace = False)\n",
        "CV_5_beta\n",
        "\n",
        "# for beta in CV_5_beta['k1'][0]:\n",
        "#   print(beta)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k1</th>\n",
              "      <th>k2</th>\n",
              "      <th>k3</th>\n",
              "      <th>k4</th>\n",
              "      <th>k5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.8665391115655625, 1.1009242364545764, 1.102...</td>\n",
              "      <td>[0.5821675881616334, 0.5780734157082644, 0.579...</td>\n",
              "      <td>[0.44399875622923, 0.4280314240447615, 0.44228...</td>\n",
              "      <td>[-0.3996372925768816, -0.4466357169428901, -0....</td>\n",
              "      <td>[0.4274866828753906, 0.4496161230514165, 0.454...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  k1  ...                                                 k5\n",
              "0  [0.8665391115655625, 1.1009242364545764, 1.102...  ...  [0.4274866828753906, 0.4496161230514165, 0.454...\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xld0mQlqzpeW"
      },
      "source": [
        "### **Cost for each K-fold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "regfNKo_qQ1Y",
        "outputId": "b02ec78c-d787-42a0-f91f-0278ac214555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "CV_5_cost = gd(X_d2, Y_d2, tune, alpha, 1000)[1].T # Cost\n",
        "CV_5_cost= (CV_5_cost).rename(columns = groups, inplace = False)\n",
        "CV_5_cost"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k1</th>\n",
              "      <th>k2</th>\n",
              "      <th>k3</th>\n",
              "      <th>k4</th>\n",
              "      <th>k5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.01</th>\n",
              "      <td>-0.007153</td>\n",
              "      <td>-0.008870</td>\n",
              "      <td>-0.006103</td>\n",
              "      <td>-0.005480</td>\n",
              "      <td>-0.006180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.10</th>\n",
              "      <td>-0.071527</td>\n",
              "      <td>-0.088704</td>\n",
              "      <td>-0.061025</td>\n",
              "      <td>-0.054804</td>\n",
              "      <td>-0.061800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.00</th>\n",
              "      <td>-0.715267</td>\n",
              "      <td>-0.887038</td>\n",
              "      <td>-0.610250</td>\n",
              "      <td>-0.548038</td>\n",
              "      <td>-0.617999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.00</th>\n",
              "      <td>-7.152670</td>\n",
              "      <td>-8.870383</td>\n",
              "      <td>-6.102501</td>\n",
              "      <td>-5.480376</td>\n",
              "      <td>-6.179986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100.00</th>\n",
              "      <td>-71.526696</td>\n",
              "      <td>-88.703829</td>\n",
              "      <td>-61.025009</td>\n",
              "      <td>-54.803758</td>\n",
              "      <td>-61.799864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000.00</th>\n",
              "      <td>-715.266960</td>\n",
              "      <td>-887.038285</td>\n",
              "      <td>-610.250089</td>\n",
              "      <td>-548.037585</td>\n",
              "      <td>-617.998636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000.00</th>\n",
              "      <td>-7152.669600</td>\n",
              "      <td>-8870.382851</td>\n",
              "      <td>-6102.500892</td>\n",
              "      <td>-5480.375848</td>\n",
              "      <td>-6179.986362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   k1           k2           k3           k4           k5\n",
              "0.01        -0.007153    -0.008870    -0.006103    -0.005480    -0.006180\n",
              "0.10        -0.071527    -0.088704    -0.061025    -0.054804    -0.061800\n",
              "1.00        -0.715267    -0.887038    -0.610250    -0.548038    -0.617999\n",
              "10.00       -7.152670    -8.870383    -6.102501    -5.480376    -6.179986\n",
              "100.00     -71.526696   -88.703829   -61.025009   -54.803758   -61.799864\n",
              "1000.00   -715.266960  -887.038285  -610.250089  -548.037585  -617.998636\n",
              "10000.00 -7152.669600 -8870.382851 -6102.500892 -5480.375848 -6179.986362"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH4SCYXnmmn6"
      },
      "source": [
        "## Deliverable 2\n",
        "\n",
        "Illustrate the effect of the tuning parameter on the cross validation error by generating a plot  with the ùë¶-axis as $CV_{(5)}$ error, and the ùë•-axis the corresponding log-scaled tuning parameter value $\\log_{10}(ùúÜ)$ that generated the particular $CV_{(5)}$ error. Label both axes. Without the log scaling of the tuning parameter, the $CV_{(5)}$ plot will look distorted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7Ocf5VwTmCr",
        "outputId": "a0ba6d12-56cb-46f3-9b51-7da42381c958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "# Initialize figure\n",
        "fig = plt.figure()\n",
        "plt.title('5-Fold Cross Validation')\n",
        "\n",
        "# Plotting\n",
        "for i in range(len(CV_5_cost.columns)):\n",
        "  # tuning parameter lambda and lambda_beta column values\n",
        "  plt.plot(tune, CV_5_cost.iloc[:, i])\n",
        "\n",
        "# Axes\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Tuning Parameter Values')\n",
        "plt.ylabel('CV5 error')\n",
        "\n",
        "# Legend\n",
        "# plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.show()\n",
        "fig.savefig('Deliverable1.jpg')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEaCAYAAADUo7pxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU13n4/88zM9oltIPQggWS2BcBMga8YVuysWMbYjuJHbexHSf5Zv8mab5t821f2dq0aZv+0rhp0iaxmzjfJo63AI63GMfgFRuM2c0iwOyLAEkgtM88vz/ulRitSGhGMxo979frvrhz5i7naNA8uvec+xxRVYwxxpih8ES6AsYYY0Y+CybGGGOGzIKJMcaYIbNgYowxZsgsmBhjjBkyCybGGGOGzIKJGTVE5H4Reb2f99eIyKeGs06RIiK/FJG/d9evFpFdA9n2Es/VICKTLnV/MzJYMDFRwf0ib3a/eBr6+3Jzt1cROR+0fd0w1HGyiDwhIqdEpF5EtojI10TEG+5z91KXu0XkAxGRbuU+ETkpIrcO9Fiq+pqqTglRvXoEZFVNVdV9oTi+iV4WTEw0+aL7xZM6wC+3OUHbZ4SzYiJSArwNHAJmqWo68BGgAkjrZXtfOOsDrAAygGu7lS8FFHghzOc3pgsLJiamiEi6iDwqIjUickBE/lZEev1/LiJVIrLTvcr4MSC9bef6DvCmqn5NVY8BqOouVf24qtaJSLF7tfSgiBwE/iQiHvf8B9yrhUdFJN09d6KI/D8ROS0idSKyXkTGue/dLyL7ROSciOwXkXu7V0ZVm4HHgU90e+sTwG9Utd29ijrutu9VEZnRx89hiYgcDno9V0Q2uuf/HZAY9F6miPzB/fnWuuuF7nvfA64GfuxeLf7YLVcRKb3Y59NxG1JEfuAee7+I3NzPZ2KiiAUTE03+0b2F9IaILLnEY/w7kA5Mwvmr/RPAA903EpEc4Gngb4EcYC9wZT/HrQSeHMD5rwWmATcB97vLdW59UoEfu9vd59azCMgGPgs0iUgK8BBws6qmAYuBTX2c61fAXSKS5LYpHbjNLQd4HigDxgIbgf+5WOVFJB7nqufXQBbwBHBn0CYe4L+By4AJQFNHm1T1b4DXuHCF+cVeTnGxz+cKYBfOZ/LPwMPdb+WZKKWqttgS8QXnSyQNSMD5oj0HlPSzvQJngTp3eQjwAq3A9KDt/hewxl2/H3jdXf8EsC5oOwEOA5/q43xtwNJ+6lPs1mlSUNnLwOeDXk9xj+MDPgm8CczudpwUtz13AkkD+LntAT7urn8a2NzHdhlu/dLd178E/t5dXwIcdtevAY4CErTvmx3b9nLccqA26PWa7j9D97ylA/x8qoPeS3b3zYv0/09bLr7YlYmJCqr6tqqeU9UWVf0V8AZwC4CIbA/qaL86aLd5qprhLl/G+Ws2DjgQtM0BoKCXU+bj9H90nF+DX/fiNDB+AE0JPkZ+L3XxAeNw/vJ/EXhMRI6KyD+LSJyqngc+hnOlckxEnhWRqf2c71Eu3Or6c/c1IuIVke+LyF4ROQt84G6Tc5H65wNH3J9HcL1xj5ssIv/l3qI6C7wKZAxwEMJAPp/jHSuq2uiupg7g2CbCLJiYaKW4fRiqOkMvdLS/1s8+p3D+8r8sqGwCcKSXbY/h3GICwL2VUtTLdh1W0/V2T3/17nC0l7q0AydUtU1Vv6Oq03FuZd2KGxRU9UVVrcIJXjuBn/dzvl8DN4jIImAhF25lfRxYhnN7Lh3nygn67xcC5+dS0O3W0oSg9b/AucK6QlXH4FzJBB+3vzTkg/l8zAhjwcREnIhkiMhNbqe0z+1wvoZBjkhSVT9Op/T3RCRNRC4Dvgb8v142fxaYISJ3uCOvvgzk9XP4bwGLReRfRCTPrXep24ne10iy3wJfFZGJIpIK/APwO3U6x68TkVnuX/Rncb5kAyIyTkSWuX0nLUADEOinzR8Ar7vneklVO/6yT3P3P41zu+gf+mlbsLdwAt6XRSRORO4AFgS9n4bTT1InIlnuzyXYCZz+kN7qOpjPx4wwFkxMNIgD/h6owfnr9UvAclXdfQnH+hJwHtiH8yX7G+CR7hup6imcob3fx/nCLcO5tdYrVd0LLML5C3+7iNQDTwEbcPp3evMIzpXDq8B+oNmtHziB60mcQPI+sNbd1oPzBXsUOIPTSf25i7T5Vzh/7T8aVPYozi2kI8AOYN1FjtHRzlbgDpz+izM4t9yeDtrk34AknM9pHT0D/o9wBgXUishDvZxiQJ+PGXmk661RY4wxZvDsysQYY8yQWTAxxhgzZBZMjDHGDJkFE2OMMUNmwcQYY8yQhTuzadTKycnR4uLiSFfDGGNGlHffffeUquZ2Lx+1waS4uJgNGzZEuhrGGDOiiMiB3srtNpcxxpghs2BijDFmyCyYGGOMGTILJsYYY4YsZoKJiCwVkV0iUi0ifx3p+hhjzGgSE8HETeP9H8DNwHTgHhGZHtlaGWPM6BErQ4MX4Ez3uQ9ARB7DmRhoR6hP9OQ//SNt51tCfdioF5xbusfsSuGYovsSDing1EWk40XHP856Zz0F6fgzyt1WEPAInXuJ817nMTv27ziWJ2g/EXcT56AeubC/87bH3VfcYo+z7gmql+fCOXy+OOKTU0hMSyM5bQypaWmkpCSRlJJKfFISnrg4xBMTfweaGBIrwaSArtOlHsaZU7wLEfkM8BmACRMmdH97QOren0BL4kBmbzVmqAJcmOLepQE8gXZE/Yi2d66j7QhOGeqHjnWcdcTvHi+AeAKAgicAHnWCmlcQd/H4vHh9gjfOg9fnxRfvxRfnIz4xjvgEH/EJ8cQnxhMXH09cUjzxCYnEJyaQkJREQlIS8YmJeOMTkLg4vFlZiHcgM/qakS5WgsmAqOrPgJ8BVFRUXNJELhOr2mg+vzOk9Yp+/fyotI/1QRxTu+94CZ+MBtQ5kqq7v7PeOV+PW+68FQB1zqoB94SqqAadPKBOvTp2d7ch6HAQcF5rx+sL+3eeNxDUzo7ja8ecxIqquHUFcffRgBLwB9B2darqBwIeNCCgAupF1QPqBbzuFZEP8BIQ51/woZIIeFF8ID5UfCheEC8qcah4UU/QV4Abd2gd/M/fmdSxBajrEvCSmk4Qx1EyC4Vpi2dQuPhKfLk9Hp42MSBWgskRus7fXUiY5pW+4d77w3FYY0IrEAB/C7Q1QXtz57/tLY1BSwPtLY00NTbS0txIU0sjrc1NtLY009rcSntrK+0t7bS3+fG3+/G3B9B2CPjBHxDwC4GAoOqFgIeA+gioDyWOgNdHQONpTiyiwXs5tfVx7HsuQOrjz5Hc8gFpWU0Uzy5iwuLFJM6YjichIdI/MTNEsRJM1gNlIjIRJ4jcDXw8slUyJoI8HvAkQVxSl2IfYfyl97dDexO0NTv/tjTQuvslajd8j12nYe+5OZzV6TSkXsFJiWfvNkh5ewdjzq4iNf40eWXpTLiiguTycuImTAjq4zIjQcxM2ysit+DMT+0FHlHV7/W3fUVFhVpuLmOGyak9sPVJ2jY9jtYdZAPTeatpEf6GSST7JyCSCEBS40ky6qsZ03yArHwPhfNnkTynnKTZs/Cmp0e4EQZARN5V1Yoe5bESTAbLgokxEaAKR9+DbU+hW59CGo7RKKk8ITeyoWka6eezGds6Di/JACQ0nyGzbo8TYJLqyZtZQurccpLmzCFh8mTEFys3V0YOCybdWDAxJsICfjjwBmx9AnashOZ6muMyeTPxan5dN5dz7WkUt3opbMohLpAKQFxrvRNc6qrJaDxAVkk2qXPmkjRnDklzZhOXlxfhRsU+CybdWDAxJoq0t0D1atj6JOx6HtqbaE4p4L0xN/DouQreOZXMBDlHccBD4flMEtvTAPC0nyOzbi9Zte7VS3IrqW5gSZozh8QZM/AkJ0e4cbHFgkk3FkyMiVIt52Dnc84Vy94/gfppz57C+zk38UTLQlbs9yHNjRR76inzeBjbkEZKi9ufEmgkrWE/Y2t2k1FXTVrTEZLKSkmaPbvz6iV+4kR76HMILJh0Y8HEmBHg/CnYscK5Yjn4FgBacDmHCm/hWf9Cnv8gwJbD9aRpG1PiGyj1QtbZZFIaM5xttYXElg/Iq6km+9Quxpw9gC81iaRZs0ic0xFg5uDLzIxkK0cUCybdWDAxZoSpOwjbnnYCy4mtzsOak5Zwrmw5azwLWL2vmVd311Db2EaKBrg8vZkJtJNam0DKOSe4BGjF6z/E2PoPGH94O+l1+/AG2oibMKHL1Uvi1KlIfHxk2xulLJh0Y8HEmBHs5PtOUNn6BNQdAG8CTL4J/8y72J58Ba/sPcfa3SfZdKiOgEJugpcrs9sZ29pM/GkPibVjEDwEaCcgh8luOkzh0V1kH9mBz9+MxMeTOG1a59VL8ty5xOXnR7rVUcGCSTcWTIyJAapw5F0nqGx7Gs6fhIQxMO12mHUntWMX8vq+OtbsqmHt7hpONThJWmeNTeXyDD9jzp8lcCJA3Ok0POolQIAW3xHS/Ucpqj3I+N3vEd9YDx4PRf/1X6RefVWEGxx5Fky6sWBiTIzxt8MHr8LWp+D9VdByFlLGwsw7YNZHCIyfx/snznUGlncP1OIPKGkJPq6amM3s1Hbi6s7QcKgFT00K3oAPJUBD/HFKjuxmZlw10x77TaRbGXEWTLqxYGJMDGtrhj1/dK5Ydr/o5CnLLIaZd8Gsj8DYqZxtbuPN6lOs3V3Dml01HKtvBmDyuFSuLclhWpLSfOIYNfsa8B1NZ+L+Z1jyj39O8rx5kW1bhFkw6caCiTGjRHM97HzWCSz71jiposfNgll3wcw7IaMIVWXPyQbW7qphze6TrN9fS6s/QFKcl8Ul2UzaVc3Y43FUJr7MxJ/+NNItiigLJt1YMDFmFGo4Cdt/73TeH37HKZuwyAks0z8MKdkAnG9p5629p52rlt0nSTlzkNvqJjB7609Z8Oj3SSgpiWAjIsuCSTcWTIwZ5c7sh21POVcsNTvB44NJ1zm3wabeAgnOU/aqyg0/eIVbDpwj/+RBlpQeJ/8f+s0jG9P6Cib2GKgxZnTKmgjXfB0+vw4++wYs/pITVH7/GfiXMnjiAdj5HOJv5fa5hWxOPcWZzGkce/E12k6cjHTto44FE2PM6CYCeTOh8tvwv7fAJ1+EuffC/rXw2D3wgzI+WfsQOzUZBI6MW0ztrx+NdK2jjgUTY4zp4PHAhIXwoX+Fv9gF9z4FZTcxZvuv+VTOZg6nH+dQ4SJO/e4J/OfORbq2UcWCiTHG9MYbB2WVcOfPIXMiNydt423xgCeNE0ll1D3+eKRrGFUsmBhjzMWUVVFUt4FjJNGQWE/1pGs5/ctfEWhtjXTNooYFE2OMuZjSKqS9iQeKjrJrTAOtiSXUN/o4+8wzka5Z1LBgYowxF1N8FXgT+HDq+7zVnI5f2tk7+XpOP/wIGghEunZRwYKJMcZcTHwyFF9FSf1b+OPjqMk9zcn0uTQeOELDmjWRrl1UsGBijDEDUVaF90w1Hyv1s14S8JLEoZIrOf2LhyNds6hgwcQYYwaitAqAezJ3sbM5gfOpdewuWEjjxo00btwY4cpFngUTY4wZiOwSyCxmSsPbjEnyUZMHcVpAXd4UTj/8SKRrF3EWTIwxZiBEoLQK7wevcfuMLF6qS6Td28qm6dfS8PLLtOzdG+kaRpQFE2OMGaiyKmhr5J68I9S1K80TGmjTabSlZHD6kdF9dWLBxBhjBqr4avAmMK3hbfLGJPJBWjY+jWfrghupX/XMqE4AacHEGGMGKj4Ziq/Es3c1t80Zz0uHm2jJrudw3HTU7x/VCSAtmBhjzGCUVsGp3dxVEqA9oEjZGFJbczl45Q3UPva7UZsA0oKJMcYMRpkzRHjy2XWU5KbwdlMSbXHNbMycQqChYdQmgLRgYowxg5FdChmXIdWrWV5ewLoDtSRPV1LPTeZ8xeWcGaUJIC2YGGPMYIg4Vyf7X+X2Wc6c8a0FE/Cql9dLZtNeUzMqE0BaMDHGmMEqrYK281x2bjNzJ2Twh321BPLP0VI7EZkyeVQmgLRgYowxgzXxavDGQ/Vqls3JZ+fxcxQvmEBqayYbFi6kdd++UZcA0oKJMcYMVnwKXHYl7HmJW+fk4/UI7wcSaUtsYtfZbHwF+aMuAaQFE2OMuRRlVXBqFzntJ7iqNIeVW46RX5HMuNpJHL75OppGWQJICybGGHMp3CzC7HmJZeX5HKlrIn/WFFRgTSANb0bGqEoAGZFgIiL/IiI7RWSLiPxeRDKC3vuGiFSLyC4RuSmofKlbVi0ifx1UPlFE3nbLfyci8cPdHmPMKJRTBhkToHo1N87IIzHOwwv7T+MrbiLt4ET8d9wyqhJARurK5CVgpqrOBnYD3wAQkenA3cAMYCnwExHxiogX+A/gZmA6cI+7LcA/AT9U1VKgFnhwWFtijBmd3CzC7FtLqtdP5bRxPLvlGFdWzSSpPZUXsjORxMRRkwAyIsFEVf+oqu3uy3VAobu+DHhMVVtUdT9QDSxwl2pV3aeqrcBjwDIREeB64El3/18By4erHcaYUa7MGSLMwbdYXl5AbWMbNUlJtKc2UrsrmdTlt4+aBJDR0GfySeB5d70AOBT03mG3rK/ybKAuKDB1lPdKRD4jIhtEZENNTU2Iqm+MGbUmXuMMEd7zEtdMziUjOY5Vm49RsjibcWeLeXNeMYySBJBhCyYislpEtvWyLAva5m+AduB/wlWPYKr6M1WtUNWK3Nzc4TilMSaWxafAZYuhejXxPg+3zBrPH7efYOE1cwh42nlvez1pS5eOigSQYQsmqlqpqjN7WVYCiMj9wK3Avaqq7m5HgKKgwxS6ZX2VnwYyRMTXrdwYY4ZHaRXU7IS6Qyybk09Tm583DteSPMXP2MOTOXHrlaMiAWSkRnMtBf4SuF1VG4PeWgXcLSIJIjIRKAPeAdYDZe7IrXicTvpVbhB6BbjL3f8+YOVwtcMYYzqyCFP9EpcXZ5GfnsiK945w/dJ5xPsTefaDI6QsXhTzCSAj1WfyYyANeElENonIfwKo6nbgcWAH8ALwBVX1u30iXwReBN4HHne3Bfgr4GsiUo3ThzK6Hjs1xkRWzmRInwB7VuPxCLeV5/PqnlOk5afjz2xEt2fg+7OPxnwCyEiN5ipV1SJVLXeXzwa99z1VLVHVKar6fFD5c6o62X3ve0Hl+1R1gXvMj6hqy3C3xxgziolAWSXsXwvtrSwvL8AfUJ7fdpzZ1xaRc76AP/hPkjBtWkwngIyG0VzGGDOylVZBawMcfIupeWlMHpfKyk1HWbxkBn5fG3vfrCXzkw/EdAJICybGGDNUHUOEq19CRFhWXsCGA7WcaGwla5aP/ONTeLckibiCgphNAGnBxBhjhiohFSYsgj2rAbh9Tj4AqzYfperm+fg0njWvbCHrgQdiNgGkBRNjjAmFsiqoeR/qD1OUlUzFZZms3HSEsUXpMK6JpD35nL2hImYTQFowMcaYUAjKIgywrDyf3Sca2Hn8HAtuKCWjeSxPv7OGzHvvjckEkBZMjDEmFHKnQHoRVDu3uj40Ox+fR1ix6QhzF5Xij2/lxPpWkj92R0wmgLRgYowxoSACpZWwbw20t5KVEs/VZTk8s+koHq+HgvkpFJ6aygtH15Nxxx0xlwDSgokxxoRKmTtE+NA6AJbPLeBofTPrPzjD9Uvn4cHL23/aRdYD98dcAkgLJsYYEyoTrwFPXGe/SeW0cSTFeVmx6SiZ41LwTWgh+4MSdsXXMSbGEkBaMDHGmFBJSIPLFnX2m6Qk+Lhxxjie23qM1vYAV1XNILU1kxV/epmsBz8ZUwkgLZgYY0wolVbByR1QfxiA5eUF1De1sXZ3DdPmFRJIaqFxcwItJQUxlQDSgokxxoRSZxZh5+rkqrIcslLiWbnpCB6vh5JFORTWTeH3G/9A1oMPxkwCSAsmxhgTSrlTYUxhZ79JnNfDh2aNZ/X7J2hoaeeaqtmoBNj66mGSFi2MmQSQFkyMMSaUOrII73OyCIPzAGNzW4A/bj9OamYCKaVK/uHpvHnoLbIffDAmEkBaMDHGmFArrYLWc3DobQDmX5ZJYWYSKzYdBeDam2aT1J7KC396gzFLb4qJBJAWTIwxJtQmXesMEa52bnWJCLfPyeeN6lPUnGth4vSx6JgWPDuyOdZ8MiYSQFowMcaYUEtIgwkLO7MIg/MAoz+gPLvlKOIRZl1TSN65STy57hky7vjwiE8AacHEGGPCobQSTm6H+iMATB6XxtS8NFZudm51XbFkKgGPn/1v1dGe4BvxCSAtmBhjTDh0GyIMztXJewfrOHD6PImpcWTPiGPC8Vn8cc9qMu/9+IhOAGnBxBhjwmHsdEjL7+w3AbitY9IstyN+ydI5xPsTWfPKRnxZWSM6AaQFE2OMCYfgIcL+NgAKMpJYMDGLFZuOoKqMn5SBJ7uVtD0T2Hl654hOAGnBxBhjwqW0ClrOdg4RBueZk70159l+9CwiQsX1peQ0FvL0G88TX1TEmKU3jcgEkBZMjDEmXCYtAY+v82l4gFtmjifOK6zc5HTMz7mymICvnZoN7ZxrPUfWgw+OyASQFkyMMSZcEsdA0cIunfCZKfFcOzmXVZuP4g8o8Yk+CuelUVwzm5Xb/kDSjBkjMgGkBRNjjAmnsko4sQ3OHu0sWlZewImzLby9/zQAV984C5/G8c7aXajqiEwAacHEGGPCqbTnEOHKaeNIifd2jurKKUwlPr+dvAPTWH9sPSmLF4+4BJD9BhMR8YjIR4erMsYYE3PGzXCGCAf1myTFe7lpRh7PbT1GS7sfgEWV00hvzmXVq6sRkRGXALLfYKKqAeAvh6kuxhgTe0Sg9AbYt6ZziDDA7eX5nG1u55WdNQBMvTwfTWineUsyJxtPOgkg8/NHTALIgdzmWi0iXxeRIhHJ6ljCXjNjjIkVZR1DhN/pLLqqNIfslHhWbXZGdfnivJRekcNlZ2bw5MaViM83ohJADiSYfAz4AvAq8K67bAhnpYwxJqZMWuIMEQ56Gt7n9XDr7PGsfv8kZ5udK5aFlVPx4GX7G0doC7SRcecdIyYB5EWDiapO7GWZNByVM8aYmJCYDkVXdMkiDLBsbgGt7QFe3HYcgIyxyaRMgglHZvPKgTV4kpNHTALIiwYTEYkTkS+LyJPu8kURiRuOyhljTMworYQTW+Hssc6iuUUZTMhKZuWmC8OGr6qcQWprBi+ueQNgxCSAHMhtrp8C84GfuMt8t8wYY8xA9ZJFWERYVp7Pm3tPcfJsMwCT5uRCSjtxO3PZV7dvxCSAHEgwuVxV71PVP7nLA8Dl4a6YMcbElHEzIW18l34TcHJ1BRSe2eJcsXi8HmZeVUBR/TSe2LASYEQkgBxIMPGLSEnHCxGZBPjDVyVjjIlBHUOE964Bf3tncenYNGbkj2GVm6sLYP6SUlQCHFx3lsa2xhGRAHIgweTrwCsiskZE1gJ/Av4iFCcXkb8QERWRHPe1iMhDIlItIltEZF7QtveJyB53uS+ofL6IbHX3eUhEJBR1M8aYkCutgpZ6OLy+S/Hy8gI2H65n/6nzAKRmJpA9LYGJx+fy7J7nAMj6ZHQngLzYE/BeYA5QBnwZ+BIwRVVfGeqJRaQIuBE4GFR8s3uuMuAzuH0z7nMt3wKuABYA3xKRTHefnwKfDtpv6VDrZowxYTFpCYi3x62u2+bkI0JnJmGAKyunk9Seytq1G1FVkmbOIHnRwqhNAHmxJ+D9wD2q2qKqW9ylJUTn/iHO0/UaVLYMeFQd64AMERkP3AS8pKpnVLUWeAlY6r43RlXXqaoCjwLLQ1Q/Y4wJraQMd4hw12CSl57IwonZrNx0FOerDIqmZuHN8JO5bxKbazYDkP2pT0VtAsiB3OZ6Q0R+LCJXi8i8jmUoJxWRZcARVd3c7a0C4FDQ68NuWX/lh3spN8aY6FRWCce3wLkTXYqXleez/9R5th6pB0A8wrwlE8k7N4mn1v0BIKoTQA4kmJQDM4DvAv/qLj+42E4islpEtvWyLAP+L/DNoVT8UojIZ0Rkg4hsqKmpGe7TG2NMr1mEAW6eOZ54r4cV71145mT2VZeh3gC1G+F00+moTgA5kD6TVap6Xbfl+osdWFUrVXVm9wXYB0wENovIB0AhsFFE8oAjQFHQYQrdsv7KC3sp76tOP1PVClWtyM3NvVgTjDEm9PJmQWpej36T9OQ4lkzJ5ZktzqRZAImpcRTOSaPk5Dye3rECIGoTQA6ozySUJ1TVrao6VlWLVbUY59bUPFU9DqwCPuGO6loI1KvqMeBF4EYRyXQ73m8EXnTfOysiC91RXJ8AVoayvsYYE1IiztPwe//UZYgwwPK5BdSca+Gtvac7yxZWTiU+kMj613bjD/ijNgFkRPpM+vEczpVLNfBz4PMAqnoG+Dtgvbt81y3D3eYX7j57gefDVDdjjAmNskporocjXXPmXj91LKkJvi6jusZNHEP8WKXg4ExeO/wagJMAMj09qhJAhq3PZKDcK5RT7rqq6hdUtURVZ6nqhqDtHlHVUnf576DyDe4ttBJV/aJ2DIUwxphoNek6Z4hwt1FdiXFels7M44Vtx2luc54NFxEW3FBGTmMBq95yto/GBJADyRrcvb9kQH0mxhhj+pCUAUULevSbgDOq61xLO6/svJCHa9oV+RDnx791DIfOOgNbM//s3qhKADmQrMHjRORhEXnefT1dRB4Mf9WMMSaGlVbCsc09hggvLskhJzWBFUG3uuITfZRcnsOk0+U8seVpgKhLADmQ21y/xOkAz3df7wa+Eq4KGWPMqNCRRXjvy12KvR7htjnjeWVnDfVNF6b5vfyGMnwax443j9Lc7mQYjqYEkAMJJjmq+jgQAFDVdizRozHGDE3ebEgd16PfBJxcXa3+AC9suzD3SXZBKqlFHiYdmccL+18EiKoEkAMJJudFJBs37UnHkN2w1soYY2JdP0OEZxemU5yd3OUBRoCFlVNIb8nlxTde7yyLlgSQAwkmX8N5/qNERN7AyX/1pbDWyhhjRoPSSmiugyPvdil2Js0qYN3+0xyvb76w+bxxSJKf5N35bD+1HSBqEkAOZDTXRuBaYDHwv4AZqrol3BUzxriEytEAABiKSURBVJiYV3IdiKfPUV2q8MzmC1cn3jgP0xcXUHxmJk+89/vO8uwHI58AciBXJqhqu6puV9Vtqtp28T2MMcZcVFImFC7otd9kUm4qswvTWbm5a4aouUuK8eDl8DvnqW9xehxSrox8AsgBBRNjjDFhUlYJxzZBQ8/hvcvKC9h25CzVJxs6y9Jzk8kqS2Dy8ctZsdvJHhUNCSAtmBhjTCR1ZhF+ucdbt80ej0foMqUvwBU3TCalLYNX39hIQJ0rkUgngBxwMBGRVDcvV0Y4K2SMMaNK3mxIGdtrv8nYMYksLslhRdCkWQDFs7LxpgXI3T+ZdcfWAUQ8AWSfwUREfhK0fhWwAycv11YRuWUY6maMMbHP47kwRDjQ8xG+28vzOXimkU2H6i7s4vVQfk0xRfVTeXr9HzrLI5kAsr8rk4VB638HLFfV63BGdn03rLUyxpjRpKwSmmp7DBEGWDozj3ifh5Wbuj5zMuvqIlSUs5u9HD9/HIhsAsiB3uYa4w4RRlX3DWI/Y4wxFzPJHSLcy6iuMYlx3DB1LH/YcpR2/4WRWikZCRTMHMOUkwt4fPsTneWRSgDZX1CYKiJbRGQrMNmdlAoR8QDxw1I7Y4wZDZKzoPDyXvtNwBnVdaqhlTeCJs0CqLihhMT2FDa8tZs2v/PURqQSQPYXTKYBtwG3AjOBjrFpWURg/nZjjIlppVVw9D1oqOnx1pIpuaQldp00C6BwcibxWXDZoXJWH7wwp3wkEkD2F0w+CvhV9YC7tAGo6ilVfXp4qmeMMaNEWaXz796eQ4QT47zcMnM8L247TlPrhU568QgV15WQ1zCRlW+/2FkeiQSQ/QWTfOAtEXlNRD4vIrnDUiNjjBmN8uZASm6v/SbgpFc53+rn5Z1d5z+ZtjgfvAE872exu3Z3Z/lwJ4DsM5io6leBCcDfArOALSLygojcJyJpw1I7Y4wZLTqHCL/c6xDhKyZlM25MQo9MwokpcUyal8Pkmgoe3/ZkZ/lwJ4Dsd1SWOyf7WlX9HFAI/BBnYqwT/e1njDHmEpR2DBHu+dCh1yPcNjuftbtPUtfYNTjMvW4icYFEdq07TkPrhdQrw5kAckBDfEVkFs6zJf8BtADfCGeljDFmVCq5vs8swgDL5xbQ5lee23q8S/m4iWNIyfNRdmwBz+y98BDjcCaA7O8J+DIR+aaIbAf+BzgP3KiqC1X1R2GtlTHGjEbJWVBQ0We/yYz8MUzKTekxqktEqLi+hOzGfF58+9XO1CvDmQCyvyuTF3CeJ/mYqs5W1X9wH1g0xhgTLmXuEOHzp3q8JSIsLy/g7f1nOFrX1OW9yQvGIfFKevVlbDixobN8uBJA9hdMlgIvqOq24EIRuVJESsJaK2OMGa1KKwHtNYswwO1z8oGuk2YBxCf6mLowj5LTc3liy4WnN4YrAWR/weSH9D7X+1ng38JTHWOMGeXGlztDhPvoNynOSaG8KIMV3XJ1Acy59jK86uP4u83UNF54+HE4EkD2F0zGqerW7oVuWXHYamSMMaOZxwMlNzhXJr0MEQbnmZP3j51l94muDyRmF6SSVZzI1OMLeXL3UxcOOQwJIPsLJv3NW5IU6ooYY4xxlVVB0xmn76QXt87OxyP06IgHmH/9JNJbcnl13QbaA+2d5Zl/di+SkBC2BJD9BZMNIvLp7oUi8imgZ55kY4wxodExRLiPUV25aQlcWZrDym6TZgGUzB2LNwkKDsxk7aG1neW+rCwy7nQTQJ4MfQLI/oLJV4AHRGSNiPyru6wFHgT+d8hrYowxxpGcBQXz++w3AVheXsDh2iY2HqztUu6N8zDzqkKKa2fy1Hsru7yX/eCDFP77Q/hyckJe5f7SqZxQ1cXAd4AP3OU7qrpIVY/3tZ8xxpgQKK1ynoTvZYgwwE0z80jweXqkVwGYdU0RgtC0LZH99fs7y+MKCkhbsgTxhH5KqoseUVVfUdV/d5c/hbwGxhhjeipzhwjv7f1rNzXBR+X0cTy79Rht/q5Pt6fnJpE3dQzTTizi8fef6HX/ULMZE40xJhqNnwvJOX32m4Bzq+vM+VZe39Pz6mXedcWktKWz8Z3dNLY1hrGiDgsmxhgTjTweKL3BzSLce16tayfnkp4U1+uorstm5RCfLkw6Mp/n9z8f7tpaMDHGmKhVWgWNp/scIhzv83DLrPH8cccJGlvbu7zn8Qjl1xRTWD+FlRuf7zHqK9QsmBhjTLQquR6Qfkd1LSvPp7HVz0s7es4MMv2qfPAoibvGs+XUljBW1IKJMcZEr5RsZ4hwP/0mC4qzGJ+eyMpe0qukpCdw2exsptZcwe+2hbcjPmLBRES+JCI7RWS7iPxzUPk3RKRaRHaJyE1B5UvdsmoR+eug8oki8rZb/jsRiR/uthhjTNiUVcGRd+H86V7f9niE2+fk8+ruGs6c7zmjYvmSCSS0J1O98QS1zbW9HCE0IhJMROQ6YBkwR1VnAD9wy6cDdwMzcLIW/0REvCLixZmY62ZgOnCPuy3APwE/VNVSoBbnoUpjjIkNpVX0N0QYYFl5Ae0B5dmtx3q8VzAlk+QcH1OOLeT31b8PWzUjdWXyOeD7qtoCoKodz/YvAx5T1RZV3Q9UAwvcpVpV96lqK/AYsExEBLge6Jj4+FfA8mFshzHGhFf+XEjO7rffZNr4NMrGprKql1FdIsLcJcXkNUzkhQ1r8PeRPHKoIhVMJgNXu7en1orI5W55AXAoaLvDbllf5dlAnaq2dyvvlYh8RkQ2iMiGmpqavjYzxpjo0SWLcO9DhEWE5XMLWP9BLYdrez5TMnXReMSn5Owv442jb4SnmmE5KiAiq0VkWy/LMsAHZAELgf8DPO5eZYSVqv5MVStUtSI3NzfcpzPGmNAoq4LGU3Cs9yHCcGHSrFWbe3bEJ6bEUVaRx5RTl/PEtqd6vB8KYQsmqlqpqjN7WVbiXEE8rY53gACQAxwBioIOU+iW9VV+GsgQEV+3cmOMiR0lNwACe1b3uUlRVjLzL8tkZS+5ugBmXVuIzx/Pqc1tXSbOCpVI3eZaAVwHICKTceaaPwWsAu4WkQQRmQiUAe8A64Eyd+RWPE4n/Sp1nsJ5BbjLPe59QNc0mcYYM9KlZEPBvH77TcB55mTXiXPsPH62x3vjiseQWZDE0sZ7yEkaxqzBYfYIMElEtuF0pt/nXqVsBx4HdgAvAF9QVb/bJ/JF4EXgfeBxd1uAvwK+JiLVOH0oDw9zW4wxJvxKq+DwBmg80+cmH5o1Hq9Hes0kLCLMWTIBafPSeLbnEOKhknA/Yh+tKioqdMOGDZGuhjHGDMzhDfCLG+DOh2HWXX1udv9/v8OeEw289pfX4fF07Yr2+wOISI/ywRCRd1W1onu5PQFvjDEjQf5cSMrq92l4cDIJH6lrYsOBng8oer2eIQWS/lgwMcaYkcDjdbIIV6/uc4gwQNX0cSTFeVnRyzMn4WTBxBhjRorSjiHCm/rcJCXBR9X0cTy39Rit7X0HnVCzYGKMMSNFqTtEuLrvIcLgjOqqa2zj1d3D93C2BRNjjBkpUnKcvpOL9JtcMzmXzOQ4VvbyAGO4WDAxxpiRpKwKjvQ/RDjO6+FDs8fz0o7jNLS097ldKFkwMcaYkaS0CjTQbxZhcDIJN7cFeGnH8WGplgUTY4wZSQrmOUOEL9JvMn9CJgUZSb0+wBgOFkyMMWYk8Xid6XwvMkTY4xFuL8/n9epTnGpoCX+1wn4GY4wxoVVWBedr4PjmfjdbXl6AP6A8u6XnpFmhZsHEGGNGmpIbnH/7ySIMMCUvjal5aawchgcYLZgYY8xIk5rrDBG+SBZhcDriNx6s4+DpnpNmhZIFE2OMGYlKq+Dw+n6HCAPcNmc8AKs2h/fqxIKJMcaMRGXuEOF9r/S7WWFmMguKs1ix6SjhzBJvwcQYY0aigvmQlHnRfhOA28vzqT7ZwI5jPSfNChULJsYYMxINcIgwOJNm+TzCyk3he+bEgokxxoxUpVVw/iQc39LvZpkp8Vw7OZdVm44SCITnVpcFE2OMGalK3SHCAxnVNbeA42ebeXt//x32l8qCiTHGjFSpY2F8+YD6TSqnjSU53hu2UV0WTIwxZiQrq4LD70BTz2l6gyXH+7hpRh7PbjlGS7s/5NWwYGKMMSNZZxbh/ocIA3y0ooiPVBTR3Br6GRh9IT+iMcaY4VNYAYkZzqiumXf0u+mikmwWlWSHpRp2ZWKMMSPZIIYIh7UaETuzMcaY0CirgoYTcGJrxKpgwcQYY0a60krn34vMDR9OFkyMMWakSx0L4+dcdPbFcLJgYowxsaC0Cg69A011ETm9BRNjjIkFZVWg/otmEQ4XCybGGBMLCiogMX1AT8OHgwUTY4yJBV7fhSHCYZy3pC8WTIwxJlaUVkHDcTg+/EOELZgYY0ys6BgiPIAswqFmwcQYY2JF2jjImx2RfhMLJsYYE0vKquDQ28M+RNiCiTHGxJLSjiHCa4b1tBEJJiJSLiLrRGSTiGwQkQVuuYjIQyJSLSJbRGRe0D73icged7kvqHy+iGx193lIRCQSbTLGmKhQeLkzRHiY+00idWXyz8B3VLUc+Kb7GuBmoMxdPgP8FEBEsoBvAVcAC4BviUimu89PgU8H7bd0mNpgjDHRx+uDSddB9cvDOkQ4UsFEgTHuejpw1F1fBjyqjnVAhoiMB24CXlLVM6paC7wELHXfG6Oq61RVgUeB5cPaEmOMiTZlVXDuGJzYNmynjNTkWF8BXhSRH+AEtMVueQFwKGi7w25Zf+WHeyk3xpjRKziLcN6sYTll2K5MRGS1iGzrZVkGfA74qqoWAV8FHg5XPbrV6TNuH82Gmpqa4TilMcYMv7Q8J4gMYxbhsAUTVa1U1Zm9LCuB+4Cn3U2fwOkHATgCFAUdptAt66+8sJfyvur0M1WtUNWK3NzcoTTPGGOiW6k7RLi5flhOF6k+k6PAte769cAed30V8Al3VNdCoF5VjwEvAjeKSKbb8X4j8KL73lkRWeiO4voEsHJYW2KMMdGorAoC7bBv7bCcLlJ9Jp8GfiQiPqAZZ+QWwHPALUA10Ag8AKCqZ0Tk74D17nbfVdUz7vrngV8CScDz7mKMMaNb4QJIcIcIT7897KeLSDBR1deB+b2UK/CFPvZ5BHikl/INwMxQ19EYY0Y0rw9KljipVVQhzI/g2RPwxhgTq0or4dxROLkj7KeyYGKMMbEqeIhwmFkwMcaYWDUmH8bNHJYhwhZMjDEmlpVWwsG3oPlsWE9jwcQYY2JZxxDh/eEdImzBxBhjYlnRFZAwJuz9JhZMjDEmlnnjYNK1Tr9JGLMIWzAxxphYV1oFZ4/AyffDdgoLJsYYE+s6hgiHccIsCybGGBPr0gtg7Iyw9ptYMDHGmNGgrBIOroOWc2E5vAUTY4wZDUqrINAWtizCFkyMMWY0mLAQ4tPC1m9iwcQYY0aDjiHCe8IzRNiCiTHGjBZlVZCQCo2nQ37oSE2OZYwxZrjNuw/m3x+WQ9uViTHGjBZhnCDLgokxxpghs2BijDFmyCyYGGOMGTILJsYYY4bMgokxxpghs2BijDFmyCyYGGOMGTLRMM68Fc1EpAY4EFSUDtQPcD0HOHWJpw4+3mC36a28e1l/rzvWg8tGYltC/Zn0V8+BbDPYtkTr/6++3huJbRnNvyvh/EwALlPV3B6lqmqLE1B/NtB1YEMozjPYbXor717W3+ug+geXjbi2hPozGe62ROv/r1hqy2j+XQnnZ9LfYre5LnhmkOuhOM9gt+mtvHtZf6+f6WObSxWptoT6MxnocULVlmj9/9XXeyOxLaP5dyWcn0mfRu1trqEQkQ2qWhHpeoRCrLQlVtoB1pZoFSttCVc77Mrk0vws0hUIoVhpS6y0A6wt0SpW2hKWdtiViTHGmCGzKxNjjDFDZsHEGGPMkFkwMcYYM2QWTEJMRJaLyM9F5HcicmOk63OpRGSSiDwsIk9Gui6XQkRSRORX7mdxb6TrMxQj/bMIFkO/H9NE5D9F5EkR+Vyk6zNU7u/LBhG59VKPYcEkiIg8IiInRWRbt/KlIrJLRKpF5K/7O4aqrlDVTwOfBT4Wzvr2JUTt2KeqD4a3poMzyHbdATzpfha3D3tlL2IwbYnGzyLYINsS8d+PvgyyHe+r6meBjwJXRqK+/bmE74C/Ah4f0knD8STkSF2Aa4B5wLagMi+wF5gExAObgenALOAP3ZaxQfv9KzAvBtrxZKQ/l0ts1zeAcneb30S67kNpSzR+FiFoS8R+P0LVDpw/Up4HPh7pug+lLUAVcDdwP3DrpZ7T1zO8jF6q+qqIFHcrXgBUq+o+ABF5DFimqv8I9LgkFBEBvg88r6obw1vj3oWiHdFoMO0CDgOFwCai8Ap8kG3ZMby1G5zBtEVE3ifCvx99GexnoqqrgFUi8izwm+Gs68UMsi2pQApOYGkSkedUNTDYc0bdL1kUKgAOBb0+7Jb15UtAJXCXiHw2nBUbpEG1Q0SyReQ/gbki8o1wV24I+mrX08CdIvJTwpxGIoR6bcsI+iyC9fW5ROvvR1/6+kyWiMhDIvJfwHORqdqg9doWVf0bVf0KTkD8+aUEEsCuTEJNVR8CHop0PYZKVU/j3NcekVT1PPBApOsRCiP9swgWQ78fa4A1Ea5GSKnqL4eyv12ZXNwRoCjodaFbNtLESju6i6V2WVuiT6y0A8LcFgsmF7ceKBORiSISj9NRtSrCdboUsdKO7mKpXdaW6BMr7YBwtyXSow6iaQF+CxwD2nDuJz7olt8C7MYZCfE3ka7naGlHLLfL2hJ9S6y0I1JtsUSPxhhjhsxucxljjBkyCybGGGOGzIKJMcaYIbNgYowxZsgsmBhjjBkyCybGGGOGzIKJiVpuTqpN7nJcRI4EvY4fxHF+ISLTQ1Qnv3v+bSLyhIgkh+K4Q6zTEhFZPMRj7BORKd3K/k1E/qqffT4QkZyhnNfEDgsmJmqp6mlVLVfVcuA/gR92vFbV1kEc51OqGqrMu03u+WcCrQwwZ5aIhDMP3hJgUMGkl/o8hvNEdMf7HuAut9yYi7JgYkYUEfmliNwV9LrB/XeJiKwRZ+a7nSLyP+50ALjlFR3bi8j3RGSziKwTkXFueYn7equI/H3HcS/iNaBURG4TkbdF5D0RWR10zG+LyK9F5A3g1yJSLCKvichGd1kcVPe1IrLSvUL4vojcKyLvuPUpcbfLFZGnRGS9u1zpphn/LPBV94rp6t62660+3dryW7pOVnUNcEBVD4jIChF5V0S2i8hnevlMiiVoEiYR+bqIfDvo5/qCu/9rIjLVLf+Ie3W3WUReHcDP2kQ5CyYmlswFvoIzL8Mkep8BLwVYp6pzgFeBT7vlPwJ+pKqzcNJP9Mv9y/5mYCvwOrBQVefi/CX/l0GbTgcqVfUe4CRQparzcL64g7PnzsEJCtOAPwcmq+oC4Bc4ads76vhDVb0cuBP4hap+QNerttd6266P+nRS1a1AQETmuEV34wQYgE+q6nygAviyiGRf7OcT5GfAl9z9vw78xC3/JnCT+zlE3UyYZvAsBb2JJe+o6mEAEdkEFON80QdrxZlNEuBdnFnmABYBy9313wA/6OMcSe6xwbkyeRiYAvxORMbjzGC3P2j7Vara5K7HAT8WkXLAD0wO2m69qh5z674X+KNbvhW4zl2vBKa7F1wAY0QktZc69rddcH26+y1wt4hsx/lZfMst/7KIfNhdLwLKgNN9HKOTe87FwBNBdUlw/30D+KWIPI4z94wZ4SyYmJGmHfeK2r2vH9wR3xK07qf3/99teiEhXV/b9KfJ7cPpJCL/Dvx/qrpKRJYA3w56+3zQ+leBEzhXIR6guY+6B4JeB4Lq6MG5Agrej6Avagaw3fnuGwd5DCeIrQW2qOoJtz2VwCJVbRSRNUBit/06PxNXx/seoK77zwtAVT8rIlcAHwLeFZH56szbYkYou81lRpoPgPnu+u04f+2HwjqcW0IQ1BE9QOlcmBfivotsd0ydmez+HGdO7sH4IxdueeFe4QCcA9IGsF2/VHUvcApnWt2OW1zpQK0bSKYCC3vZ9QQwVpzRdwm400Cr6llgv4h8xK2HdNxGE5ESVX1bVb8J1NB1ng0zAlkwMSPNz4FrRWQzzq2p/v7SHoyvAF8TkS1AKVA/iH2/jXMr512cL+O+/AS4z637VAZf9y8DFSKyRUR2cGEk2TPAhzs64PvZbiB+69at49bTC4BPLszdvq77DqraBnwXeAd4CdgZ9Pa9wINum7fjzDkO8C/u4IJtwJvA5kHU0UQhS0FvDCDO8yJNqqoicjdwj6ouu9h+xhiH9ZkY45iP0zkuQB3wyQjXx5gRxa5MjDHGDJn1mRhjjBkyCybGGGOGzIKJMcaYIbNgYowxZsgsmBhjjBkyCybGGGOG7P8HAQOFoKRE6m4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEjO_9Umnm6E"
      },
      "source": [
        "# Deliverable 3\n",
        "\n",
        "Indicate the value of ùúÜ that generated the smallest $CV_{(5)}$ error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANZ7dkyCZZdf",
        "outputId": "58293e53-bbf8-43fd-d714-9ddf8f1ea54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# We need to find the minimum value of all the rows\n",
        "# Then the row with the smallest set of values, \n",
        "# will correspond to the lambda which generated the smallest error.\n",
        "\n",
        "# Get minimum errors list for every fold in Cost dataframe\n",
        "for row,column in CV_5_cost.iterrows():\n",
        "  min1 = min(CV_5_cost['k1']) # k1\n",
        "  min2 = min(CV_5_cost['k2']) # k2\n",
        "  min3 = min(CV_5_cost['k3']) # k3\n",
        "  min4 = min(CV_5_cost['k4']) # k4\n",
        "  min5 = min(CV_5_cost['k5']) # k5\n",
        "  Total_Min = pd.Series([min1,min2,min3,min4,min5])\n",
        "\n",
        "# Get minimum error of all folds minimums errors list\n",
        "print('All Minimums for each fold')\n",
        "print(Total_Min.values)\n",
        "min_found =  min(Total_Min)\n",
        "print('min:', min_found)\n",
        "\n",
        "# Get lambda Value that corresponds to the minimum error\n",
        "for i in range(len(Total_Min)):\n",
        "  if Total_Min[i] == min_found:\n",
        "    print('index:', i)\n",
        "\n",
        "# CV_5_cost.iloc[0,i]\n",
        "lowest_error_lambda = tune[i]\n",
        "print('Lambda Value Found that generated the smallest CV(5) error was', lowest_error_lambda)\n",
        "import math\n",
        "print('That is Lambda 10^', math.log10(lowest_error_lambda))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All Minimums for each fold\n",
            "[-7152.66960011 -8870.38285108 -6102.50089151 -5480.37584775\n",
            " -6179.98636228]\n",
            "min: -8870.382851082506\n",
            "index: 1\n",
            "Lambda Value Found that generated the smallest CV(5) error was 100\n",
            "That is Lambda 10^ 2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VK1diFTnp57"
      },
      "source": [
        "# Deliverable 4\n",
        "\n",
        "Given the optimal ùúÜ, retrain your model on the entire dataset of ùëÅ = 400 observations and provide the estimates of the ùëù = 9 best-fit model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZSMiNUkfBoj",
        "outputId": "4acdc943-2ed3-466d-885d-39ce855675ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "best_lambda = [10**2]\n",
        "retrain = gd(X,Y,best_lambda,alpha,1000)\n",
        "print('Retrained with the best lambda value, we get the following gradient descent:')\n",
        "col = pd.Series(['b1', 'b2','b3','b4','b5','b6','b7','b8', 'b9'])\n",
        "d4 = pd.DataFrame(retrain[0])\n",
        "d4 = d4.T\n",
        "d4.rename(columns = col, inplace = False)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrained with the best lambda value, we get the following gradient descent:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>b1</th>\n",
              "      <th>b2</th>\n",
              "      <th>b3</th>\n",
              "      <th>b4</th>\n",
              "      <th>b5</th>\n",
              "      <th>b6</th>\n",
              "      <th>b7</th>\n",
              "      <th>b8</th>\n",
              "      <th>b9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.810669</td>\n",
              "      <td>3.847291</td>\n",
              "      <td>2.62477</td>\n",
              "      <td>1.274856</td>\n",
              "      <td>-0.449715</td>\n",
              "      <td>-0.851278</td>\n",
              "      <td>-0.056418</td>\n",
              "      <td>1.836848</td>\n",
              "      <td>-0.736744</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         b1        b2       b3  ...        b7        b8        b9\n",
              "0  1.810669  3.847291  2.62477  ... -0.056418  1.836848 -0.736744\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnPbURqPnnqH"
      },
      "source": [
        "# Deliverable 5\n",
        "\n",
        "***Provide all your source code that you wrote from scratch to perform all analyses (aside from plotting scripts, which you do not need to turn in) in this assignment, along with instructions on how to compile and run your code.***\n",
        "\n",
        "For the Ridge Regression Fitting, we have the following functions with their titles that compute the following:\n",
        "\n",
        "1.   Prediction function: *total_predict*\n",
        "2.   RSS Function: *residual*\n",
        "3.   Cost Function: *cost*\n",
        "4.   Gradient Descent: *gd*\n",
        "\n",
        "Under each function are listed the description of each parameter necessary to run the function's algorithm. Underneath each function is also listed the \"Output\" that is a designated sample instructions/method as on how to use the function.\n",
        "\n",
        "```\n",
        "# Source Codes Listed\n",
        "\n",
        "# Prediction Function\n",
        "def total_predict(X, B):\n",
        "  '''\n",
        "    This function computes the dot product between the rows of design matrix and parameters column vector.\n",
        "    It uses the predict function to iterate through each row of design matrix.\n",
        "    :param X: training_data as pandas dataframe (i.e our Nxp design matrix)\n",
        "    :param B: is parameters_vector as pandas dataframe syntax (i.e p-dimensional B)\n",
        "    :return: predictions vector (i.e. dot product of X and beta parameters vector)\n",
        "  '''\n",
        "      # Corrective measure: Double check appropriate dimensions of dataframes\n",
        "  dim1 = X.shape[1]\n",
        "  dim2 = B.shape[0]\n",
        "  if  (dim1) == (dim2):\n",
        "    predictions = X.dot(B.to_numpy())\n",
        "    return (predictions)\n",
        "  else:\n",
        "    print('Cannot compute. Please check Dimensions!')\n",
        "    print('Dimensions of design matrix Nxp: ', X.shape)\n",
        "    print('Dimensions of Initialized Parameter Vector: (', len(B), 'x 1)')\n",
        "\n",
        "# Output\n",
        "yhat = total_predict(X, beta)\n",
        "print('Total predictions, yhat:')\n",
        "print(yhat)\n",
        "print('')\n",
        "print('yhat Transposed First few entries:')\n",
        "print((yhat.T).head(3))\n",
        "\n",
        "---\n",
        "\n",
        "# RSS Function\n",
        "def residual(Y, yhat):\n",
        "  ''' \n",
        "  :param Y: true values\n",
        "  :param yhat: predictions (i.e. dot product of X and parametric vector beta)\n",
        "  :return: residual sum of sqaures\n",
        "  '''\n",
        "  dim1 = Y.shape\n",
        "  dim2 = yhat.shape\n",
        "  print(\"Y and yhat Dimensions Check:\")\n",
        "  print(dim1, 'and', dim2)\n",
        "  rss = pd.DataFrame((Y.values - yhat.values)**2)\n",
        "  return rss\n",
        "\n",
        "# Output\n",
        "residual_result = residual(Y,yhat)\n",
        "print('rss:', residual_result)\n",
        "\n",
        "---\n",
        "\n",
        "# Cost Function\n",
        "def cost(rss, tuning, b):\n",
        "  ''' \n",
        "  :param b: parametric_vector_B\n",
        "  :param rss: residual sum of squares \n",
        "  :param tuning: tuning_parameter_vector\n",
        "  :return: minimum cost computation\n",
        "  '''\n",
        "  # Checking pandas DataFrame dimensions\n",
        "  tuning = pd.DataFrame(tuning)\n",
        "  dim1, dim2, dim3 = rss.shape, tuning.shape, b.shape\n",
        "  print('')\n",
        "  print('rss Dimensions Check:', dim1)\n",
        "  print('tuning parameter vector Dimensions Check:', dim2)\n",
        "  print('b randomized vector Dimensions Check:', dim3)\n",
        "  print('')\n",
        "  # Cost Computation\n",
        "  tobesummed = []\n",
        "  for j in range(len(b)):\n",
        "    compute = tuning @ ((b.iloc[j])**2)\n",
        "    tobesummed.append(compute)\n",
        "  regularization = sum(tobesummed)\n",
        "  total_cost = rss.values + ((regularization).T).values\n",
        "  # Convert to pandas Dataframe syntax\n",
        "  return pd.DataFrame(total_cost)\n",
        "\n",
        "# Output\n",
        "rss1 = residual(Y, yhat)\n",
        "cost_result = cost(rss1, tune, beta)\n",
        "print('Cost Function Computation:')\n",
        "print(cost_result)\n",
        "\n",
        "---\n",
        "\n",
        "# Gradient Descent Function\n",
        "def gd(X,Y,tune,alpha,max_iter):\n",
        "  '''\n",
        "  :param X: our standardized Nxp design matrix, <class 'pandas.core.frame.DataFrame>\n",
        "  :param Y: our N-dimensional centered y\n",
        "  :param beta: our randomply initialized parametric vector B\n",
        "  :param max_iter: max iterations alloted for convergence\n",
        "  :param alpha: proof of when convergence occurs (i.e. 2*alpha*lambda <1)\n",
        "  :param L: lambda value in tuning parameter vector\n",
        "  :return beta_update, cost: total gradient calculation and cost computation\n",
        "\n",
        "  This function is used for 'training' phase/step.\n",
        "  '''\n",
        "  # Computations\n",
        "  b = pd.DataFrame(data=np.random.uniform(-1, 1, X.shape[1]))\n",
        "  XB = pd.DataFrame((X.values).dot(b.values))\n",
        "  Y_minus_XB = pd.DataFrame(Y.values - XB.values)\n",
        "  X_T_dotprod_Y_minus_XB = (X.T).dot(Y_minus_XB)\n",
        "\n",
        "  # Change to dataframe syntax for computations\n",
        "  tuning = pd.DataFrame(tune)\n",
        "  Lb = tuning.dot(b.T)\n",
        "  # Making pretty dataframe for lambabeta - for faster computations\n",
        "  d = pd.Series(tune)\n",
        "  lambda_beta_df = (Lb.T).rename(columns = d, inplace = False)\n",
        "  # We will use this dataframe to plot a graph later\n",
        "\n",
        "  # Iterate for every column in lambda_beta dataframe and subtract XB column\n",
        "  for i in lambda_beta_df.columns:\n",
        "    compute = lambda_beta_df[i].values - (X_T_dotprod_Y_minus_XB.iloc[:,0].values)\n",
        "\n",
        "  # Iterate for 1000 iterations - this yields convergence by given assumption\n",
        "  for iteration in range(max_iter):\n",
        "    b_temp = (2*alpha)*(pd.DataFrame(compute))\n",
        "    b_update = b - b_temp\n",
        "  return b_update, lambda_beta_df # return new updated beta vector\n",
        "\n",
        "# Output\n",
        "gd_computation = (gd(X, Y, tune, alpha, 1000)[0])\n",
        "to_plot = (gd(X, Y, tune, alpha, 1000)[1])\n",
        "print('For gradient descent:')\n",
        "print(gd_computation)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aho1omjKjJ76"
      },
      "source": [
        "For the Cross Validation, listed below are the algorithms source codes. Functions listed are as follows:\n",
        "\n",
        "\n",
        "\n",
        "1.   Cross Validation Split Function: *cross_validation_split*\n",
        "2.   Cross Validation Function: *CV*\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Set K parameter for K-fold Cross Validation\n",
        "K = 5\n",
        "\n",
        "# Import Library for randomization\n",
        "import random\n",
        "from random import randrange\n",
        "\n",
        "# Cross Validation Split Function\n",
        "def cross_validation_split(dataset, folds= K):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / folds)\n",
        "\tfor i in range(folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        "\n",
        "  ---\n",
        "# Cross Validation Algorithm\n",
        "def CV(X_d2, Y_d2, tune, alpha):\n",
        "  ''' \n",
        "  Cross Validation Function \n",
        "  :param X_d2: k-fold data dataframe\n",
        "  :param Y_d2: true values fold data dataframe\n",
        "  :param tune: tuning parameter of lambda values\n",
        "  :param alpha: learning rate\n",
        "  :return: beta updated dataframe for each fold, cost dataframe for each fold\n",
        "  '''\n",
        "  CV_5 = (gd(X_d2, Y_d2, tune, alpha, 1000))\n",
        "  cv_beta = CV_5[0] # beta_update\n",
        "  CV_5_beta = (cv_beta).rename(columns = groups, inplace = False)\n",
        "  CV_5_cost = CV_5[1]\n",
        "  CV_5_cost = (CV_5_cost.T).rename(columns = groups, inplace = False)\n",
        "  return CV_5_beta, CV_5_cost\n",
        "\n",
        "# Output for Viewing\n",
        "# print('Cross Validation beta updates for each k-fold:')\n",
        "# print(CV(X_d2, Y_d2, tune, alpha)[0])\n",
        "# print('')\n",
        "# print('Cost for each CV fold')\n",
        "# print(CV(X_d2, Y_d2, tune, alpha)[1])\n",
        "\n",
        "# Recommended Visual Output for Viewing for beta updates output:\n",
        "\n",
        "CV_5 = (gd(X_d2, Y_d2, tune, alpha, 1000)[0]) # beta_update\n",
        "CV_5_beta = (CV_5.T).rename(columns = groups, inplace = False)\n",
        "CV_5_beta\n",
        "\n",
        "# Recommended Visual Output for Viewing for K-folds cost output:\n",
        "\n",
        "CV_5_cost = gd(X_d2, Y_d2, tune, alpha, 1000)[1].T # Cost\n",
        "CV_5_cost= (CV_5_cost).rename(columns = groups, inplace = False)\n",
        "CV_5_cost\n",
        "\n",
        "```\n",
        "You will need to initialize the folds as follows to use the Cross Validation functions mentioned above:\n",
        "\n",
        "```\n",
        "# Grabbing 5 data folds from X data\n",
        "random.seed(1)                                # random seed\n",
        "                                              # d2 = (training_data.iloc[:,: -1]).values \n",
        "                                              # .values turnes into np array\n",
        "d2 = X.values\n",
        "X_folds = cross_validation_split(d2, K)       # cross validation\n",
        "X_folds_df = (pd.DataFrame(X_folds))          # convert to dataframe\n",
        "X_folds_df.T                                  # Transposed dataframe\n",
        "                                              # Note: fold_size = total_rows / total_folds\n",
        "groups = pd.Series(['k1', 'k2', 'k3', 'k4', 'k5'])\n",
        "X_d2 = (X_folds_df.T).rename(columns = groups, inplace = False)\n",
        "X_d2 \n",
        "\n",
        "---\n",
        "\n",
        "# Grab the 5 datafolds for true value Y data\n",
        "random.seed(1)                                   # random seed\n",
        "# balance = (clean['Balance']).values          # np array\n",
        "balance = Y.values\n",
        "Y_folds = cross_validation_split(balance, K)   # cross validation\n",
        "Y_folds_df = (pd.DataFrame(Y_folds))      # convert to dataframe\n",
        "Y_folds_df.T                              # Transposed dataframe dim: 80 x 5 \n",
        "# Note: there are 80 rows per fold as we expected: fold_size = total_rows / K\n",
        "Y_d2 = (Y_folds_df.T).rename(columns = groups, inplace = False)\n",
        "Y_d2\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    }
  ]
}